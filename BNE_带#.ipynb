{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Nmbq-0wgYy"
   },
   "source": [
    "# Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true
    },
    "id": "L_JG6Hqn13o7"
   },
   "outputs": [],
   "source": [
    "# # GP configs.\n",
    "# y_noise_std = 0.1  # @param\n",
    "# hidden_units = 128  # @param\n",
    "# lengthscale=1.  # @param\n",
    "# l2_regularizer=0.1  # @param\n",
    "\n",
    "# DEFAULT_GP_CONFIG = dict(lengthscale=lengthscale,\n",
    "#                          l2_regularizer=l2_regularizer, \n",
    "#                          hidden_units=hidden_units, \n",
    "#                          y_noise_std=y_noise_std)\n",
    "\n",
    "# # BNE model configs.\n",
    "# estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "# estimate_variance = \"False\" # @param [\"True\", \"False\"]\n",
    "# estimate_skewness = \"False\" # @param [\"True\", \"False\"]\n",
    "# variance_prior_mean=0. # @param\n",
    "# skewness_prior_mean=0. # @param\n",
    "\n",
    "# estimate_mean = eval(estimate_mean)\n",
    "# estimate_variance = eval(estimate_variance)\n",
    "# estimate_skewness = eval(estimate_skewness)\n",
    "\n",
    "# DEFAULT_BNE_CONFIG = dict(estimate_mean=estimate_mean,\n",
    "#                           estimate_variance=estimate_variance,\n",
    "#                           estimate_skewness=estimate_skewness,\n",
    "#                           variance_prior_mean=variance_prior_mean,\n",
    "#                           skewness_prior_mean=skewness_prior_mean)\n",
    "# # MAP configs.\n",
    "# map_step_size=0.1 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# DEFAULT_MAP_CONFIG = dict(learning_rate=map_step_size,\n",
    "#                           num_steps=map_num_steps)\n",
    "# # MCMC configs.\n",
    "# mcmc_step_size=0.1 # @param\n",
    "# mcmc_sample_size=500 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "# mcmc_burnin=2_500 # @param\n",
    "# mcmc_nchain=10 # @param\n",
    "# mcmc_seed=0 # @param\n",
    "\n",
    "# DEFAULT_MCMC_CONFIG = dict(step_size=mcmc_step_size, \n",
    "#                            num_steps=mcmc_sample_size, \n",
    "#                            burnin=mcmc_burnin, \n",
    "#                            nchain=mcmc_nchain, \n",
    "#                            seed=mcmc_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAYcMR698j6J"
   },
   "source": [
    "# Experiment II: 2D Spatial Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AMIJk1OdKIj7"
   },
   "outputs": [],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = 1. # @param\n",
    "bma_gp_l2_regularizer = 0.1 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9iyxQiCJKIn7"
   },
   "outputs": [],
   "source": [
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 4 # 5. # @param\n",
    "bne_gp_l2_regularizer = 5 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ojX6KEmzKSEu"
   },
   "outputs": [],
   "source": [
    "# bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "#                 gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "#                 y_noise_std=y_noise_std,\n",
    "#                 map_step_size=map_step_size,\n",
    "#                 map_num_steps=map_num_steps,\n",
    "#                 mcmc_step_size=mcmc_step_size,\n",
    "#                 mcmc_num_steps=mcmc_num_steps,\n",
    "#                 mcmc_initialize_from_map=False,\n",
    "#                 #return_weight_samples=True,\n",
    "#                 n_samples_eval=bma_n_samples_eval,\n",
    "#                 n_samples_train=bma_n_samples_train,\n",
    "#                 n_samples_test=bma_n_samples_test,\n",
    "#                 seed=bma_seed)\n",
    "\n",
    "\n",
    "# bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "#                   gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "#                   variance_prior_mean=bne_variance_prior_mean,\n",
    "#                   skewness_prior_mean=bne_skewness_prior_mean,\n",
    "#                   map_step_size=map_step_size,\n",
    "#                   map_num_steps=map_num_steps,\n",
    "#                   mcmc_step_size=mcmc_step_size,\n",
    "#                   mcmc_num_steps=mcmc_num_steps,\n",
    "#                   mcmc_nchain=mcmc_nchain,\n",
    "#                   mcmc_burnin=mcmc_burnin,\n",
    "#                   mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "#                   seed=bne_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training/prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(55, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(84421, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred longitude max and min -69.93 -73.5\n",
      "pred latitude max and min 44.3 40.6\n",
      "train longitude max and min -70.023598 -73.443056\n",
      "train latitude max and min 44.107524 40.74529\n"
     ]
    }
   ],
   "source": [
    "training_eastMA = pd.read_csv('./data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('./data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('./data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "display(training_eastMA.shape, training_eastMA_folds.shape, base_model_predictions_eastMA.shape)\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 center and scale:  [-72.185104  42.680347] [3.5699997 3.7000008]\n"
     ]
    }
   ],
   "source": [
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([51, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([84421, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "#base_preds_test\n",
    "display(base_preds_train.shape, base_preds_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimization configs. \n",
    "# # Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# # mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "# map_step_size=5e-4   # @param\n",
    "# map_num_steps=10_000  # @param\n",
    "\n",
    "# mcmc_step_size=1e-4 # @param\n",
    "# mcmc_num_steps=1000 # @param\n",
    "\n",
    "# mcmc_nchain=1 # @param\n",
    "# mcmc_burnin=100 # @param\n",
    "# bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "# bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n",
    "\n",
    "# # BMA parameters.\n",
    "# y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "# bma_gp_lengthscale = 1. # @param\n",
    "# bma_gp_l2_regularizer = 0.1 # @param\n",
    "\n",
    "# bma_n_samples_train = 100 # @param\n",
    "# bma_n_samples_eval = 250 # @param\n",
    "# bma_n_samples_test = 250 # @param\n",
    "# bma_seed = 0 # @param\n",
    "\n",
    "# # BNE parameters.\n",
    "# bne_gp_lengthscale = 4 # 5. # @param\n",
    "# bne_gp_l2_regularizer = 5 # 15 # @param\n",
    "# bne_variance_prior_mean = -2.5 # @param\n",
    "# bne_skewness_prior_mean = -2.5 # @param\n",
    "# bne_seed = 0 # @param\n",
    "\n",
    "# bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "#                 gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "#                 y_noise_std=y_noise_std,\n",
    "#                 map_step_size=map_step_size,\n",
    "#                 map_num_steps=map_num_steps,\n",
    "#                 mcmc_step_size=mcmc_step_size,\n",
    "#                 mcmc_num_steps=mcmc_num_steps,\n",
    "#                 mcmc_initialize_from_map=False,\n",
    "#                 n_samples_eval=bma_n_samples_eval,\n",
    "#                 n_samples_train=bma_n_samples_train,\n",
    "#                 n_samples_test=bma_n_samples_test,\n",
    "#                 seed=bma_seed)\n",
    "\n",
    "# bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "#                   gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "#                   variance_prior_mean=bne_variance_prior_mean,\n",
    "#                   skewness_prior_mean=bne_skewness_prior_mean,\n",
    "#                   map_step_size=map_step_size,\n",
    "#                   map_num_steps=map_num_steps,\n",
    "#                   mcmc_step_size=mcmc_step_size,\n",
    "#                   mcmc_num_steps=mcmc_num_steps,\n",
    "#                   mcmc_nchain=mcmc_nchain,\n",
    "#                   mcmc_burnin=mcmc_burnin,\n",
    "#                   mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "#                   seed=bne_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model configs.\n",
    "# y_noise_std = 0.1  # @param\n",
    "# lengthscale=1.  # @param\n",
    "# l2_regularizer=0.1  # @param\n",
    "\n",
    "# # MCMC configs.\n",
    "# map_step_size=0.1 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=0.1 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "# Posterior configs.\n",
    "# bma_n_samples_train = 100 # @param\n",
    "# bma_n_samples_test = 200 # @param\n",
    "# bma_n_samples_eval = 1000  # @param\n",
    "\n",
    "bma_seed = 0  # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengthscale': 1.0,\n",
       " 'l2_regularizer': 0.1,\n",
       " 'hidden_units': 128,\n",
       " 'y_noise_std': 0.01}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005, 'num_steps': 10000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.0001, 'num_steps': 1000, 'burnin': 100, 'nchain': 1, 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bma_model_config, map_config, mcmc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('gp_weights', ()), ('y', ('gp_weights',)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior, bma_gp_config = bma_dist(X_train1, \n",
    "                                    base_preds_train, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "bma_model_config.update(bma_gp_config)\n",
    "\n",
    "# Check if the model graph is specified correctly.\n",
    "bma_prior.resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengthscale': 1.0,\n",
       " 'l2_regularizer': 0.1,\n",
       " 'hidden_units': 128,\n",
       " 'y_noise_std': 0.01,\n",
       " 'units': 3,\n",
       " 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005, 'num_steps': 10000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.0001, 'num_steps': 1000, 'burnin': 100, 'nchain': 1, 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bma_model_config, map_config,mcmc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t460112.65625...219401.53125...212203.140625...209785.0...207888.84375...206026.765625...204268.6875...202721.328125...201476.09375...200577.78125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9930249452590942\n"
     ]
    }
   ],
   "source": [
    "bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, None, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for BAE/BNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "means_train_mcmc, X_train_mcmc, Y_train_mcmc = make_bma_samples(\n",
    "    X_train1, Y_train, base_preds_train, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_train,\n",
    "    seed=bma_seed, \n",
    "    prepare_mcmc_training=True)\n",
    "\n",
    "# Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "# It is used to generate final examples in `make_bne_samples()`.\n",
    "means_test_mcmc = make_bma_samples(\n",
    "    X_test1, None, base_preds_test, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_test,\n",
    "    seed=bma_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5100, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([5100, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([5100, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([250, 84421, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(means_train_mcmc.shape, X_train_mcmc.shape, Y_train_mcmc.shape, means_test_mcmc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Additive Ensemble\n",
    "\n",
    "Given $\\mu(x)$ the posterior of a Bayesian ensemble model, the Bayesian Additive Ensemble is defined as:    \n",
    "\n",
    "$y \\sim N(\\mu(x) + r(x), \\sigma^2)$\n",
    "\n",
    "$r \\sim GaussianProcess(0, k)$\n",
    "\n",
    "The additive ensemble $r(x)$ services two purposes: \n",
    "\n",
    "1. Mitigates systematic bias in model prediction; \n",
    "2. Quantifies the model's epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # BNE GP Configs.\n",
    "# # lengthscale = 1. # @param\n",
    "# # l2_regularizer = 10. # @param\n",
    "\n",
    "# BNE model configs. \n",
    "# If estimate_mean=False, only estimates a constant variance on top of the \n",
    "# original model.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "# # MAP and MCMC configs\n",
    "# map_step_size=0.1 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=1e-2 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "                          l2_regularizer=bne_gp_l2_regularizer))\n",
    "bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "                             variance_prior_mean=variance_prior_mean,\n",
    "                             **bne_gp_config))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n"
     ]
    }
   ],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionNamedAutoBatched 'JointDistributionNamedAutoBatched' batch_shape=[] event_shape={gp_weights: [128, 2], y: [5100, 1]} dtype={gp_weights: float32, y: float32}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'estimate_mean': True,\n",
       " 'estimate_variance': False,\n",
       " 'estimate_skewness': False,\n",
       " 'variance_prior_mean': 0.0,\n",
       " 'skewness_prior_mean': 0.0,\n",
       " 'lengthscale': 4,\n",
       " 'l2_regularizer': 5,\n",
       " 'hidden_units': 128,\n",
       " 'y_noise_std': -1.0,\n",
       " 'units': 2,\n",
       " 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005, 'num_steps': 10000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.0001, 'num_steps': 1000, 'burnin': 100, 'nchain': 1, 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bne_prior, bne_model_config, map_config, mcmc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t8179.416015625...7424.173828125...7413.3544921875...7408.68017578125...7407.556640625...7407.45703125...7407.45458984375...7407.4541015625...7407.45361328125...7407.4541015625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.999812126159668\n"
     ]
    }
   ],
   "source": [
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bae = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bae = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "\n",
    "# dealing with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005235664112010045"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentile of NAN\n",
    "np.sum(np.isnan(np.mean(bne_joint_samples['mean_original'], axis=0)))/84421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Nonparametric Ensemble (Variance Only)\n",
    "So far, we are only estimating the mean-component of the model, i.e., we are assuming: \n",
    "\n",
    "$y \\sim Gaussian(m(x), \\sigma^2); \\quad m(x) = GP(0, k)$.\n",
    "\n",
    "By doing so, the model is implicitly assuming the distribution of $y$ is always a symmetric Gaussian distribution with constant mean across space and time. As a result, our model can only quantify model uncertainty (due to lack of data) via the GP prior, but cannot flexibly capture the data uncertainty that is inherent to the empirical distribution of y.\n",
    "\n",
    "To resolve this, we extend the ensemble's outcome distribution $y | f$ by also estimating the higher moments of the data distribution (e.g., variance, skewness, etc) using flexible estimators. Specifically, we specify the outcome distribution family to the [maximum-entropy distribution](https://en.wikipedia.org/wiki/Principle_of_maximum_entropy) given the known moments, so the predictive distribution is [minimax](https://arxiv.org/pdf/math/0410076.pdf) and still statistically efficient to estimate.\n",
    "\n",
    "For example, when we want to estimate the first two moments (mean and variance) of the distribution, this leads to a Gaussian distribution with spatio-temporally adaptive variance $\\sigma(x)^2$:\n",
    "\n",
    "$$y \\sim Gaussian(m(x), \\sigma(x)^2); \\quad \\mbox{where} \\quad m \\sim GP(0, k_m), \\sigma \\sim GP(0, k_\\sigma)$$\n",
    "\n",
    "and when we want to estimate the first three moments (mean and variance) of the distribution, this leads to a [Exponentially-modifed Gaussian](https://en.wikipedia.org/wiki/Exponentially_modified_Gaussian_distribution) (EMG) distribution with spatio-temporally adaptive variance $\\sigma(x)^2$ and skewness $\\lambda(x)$:\n",
    "\n",
    "$$y \\sim EMG(m(x), \\sigma(x)^2, \\lambda(x)); \\quad \\mbox{where} \\quad m \\sim GP(0, k_m), \\sigma \\sim GP(0, k_\\sigma), \\lambda \\sim GP(0, k_\\lambda)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Default configs\n",
    "# # BNE GP Configs.\n",
    "# lengthscale = 1. # @param\n",
    "# l2_regularizer = 10. # @param\n",
    "\n",
    "# # BNE model configs.\n",
    "# variance_prior_mean=0. # @param\n",
    "# # MAP and MCMC configs\n",
    "\n",
    "# map_step_size=5e-3 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=1e-2 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "\n",
    "# bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "# bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "# map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "# mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "# bne_gp_config.update(dict(lengthscale=lengthscale, \n",
    "#                           l2_regularizer=l2_regularizer))\n",
    "# bne_model_config.update(dict(estimate_variance=True,\n",
    "#                              variance_prior_mean=variance_prior_mean,\n",
    "#                              **bne_gp_config))\n",
    "\n",
    "# map_config.update(dict(learning_rate=map_step_size,\n",
    "#                        num_steps=map_num_steps))\n",
    "# mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "#                         num_steps=mcmc_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model & Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t8037.125...7418.61328125...7407.44384765625...7404.9677734375...7404.70751953125...7404.7001953125...7404.69921875...7404.69921875...7404.69921875...7404.69921875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9998054504394531\n"
     ]
    }
   ],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "\n",
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bne_vo = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bne_vo = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88_VOXlgq9n_"
   },
   "source": [
    "## Bayesian Nonparametric Ensemble (Variance + Skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BNE GP Configs.\n",
    "# lengthscale = 1. # @param\n",
    "# l2_regularizer = 10. # @param\n",
    "\n",
    "# # BNE model configs.\n",
    "# variance_prior_mean=0. # @param\n",
    "# skewness_prior_mean=0. # @param\n",
    "# # MAP and MCMC configs\n",
    "# map_step_size=5e-3 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=1e-2 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "# bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "# bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "# map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "# mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "# bne_gp_config.update(dict(lengthscale=lengthscale, \n",
    "#                           l2_regularizer=l2_regularizer))\n",
    "# bne_model_config.update(dict(estimate_variance=True,\n",
    "#                              estimate_skewness=True,\n",
    "#                              variance_prior_mean=variance_prior_mean,\n",
    "#                              skewness_prior_mean=skewness_prior_mean,\n",
    "#                              **bne_gp_config))\n",
    "\n",
    "# map_config.update(dict(learning_rate=map_step_size,\n",
    "#                        num_steps=map_num_steps))\n",
    "# mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "#                         num_steps=mcmc_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model & Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t8433.4580078125...7424.66162109375...7411.59375...7406.24609375...7404.80908203125...7404.61962890625...7404.6123046875...7404.61328125...7404.61328125...7404.61328125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9998044967651367\n"
     ]
    }
   ],
   "source": [
    "# Construct prior distribution.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bne_vs = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bne_vs = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_DATA_ADDR_PREFIX = \"./example/data\"\n",
    "# Tuning Parameters\n",
    "BMA_lenthscale = bma_gp_lengthscale\n",
    "BNE_lenthscale = bne_gp_lengthscale\n",
    "BMA_L2 = bma_gp_l2_regularizer\n",
    "BNE_L2 = bne_gp_l2_regularizer\n",
    "_SAVE_ADDR_PREFIX = \"./pic/BMA_lenthscale_{}_L2_{}_BNE_lenthscale_{}_L2_{}\".format(BMA_lenthscale, BMA_L2, BNE_lenthscale, BNE_L2)\n",
    "\n",
    "path=_SAVE_ADDR_PREFIX\n",
    "isExists=os.path.exists(path) #判断路径是否存在，存在则返回true\n",
    "\n",
    "if not isExists:\n",
    "    os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The predictive surface of individual base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "monitors = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "\n",
    "base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]] = np.where(np.isnan(base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]]), 0, base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]])\n",
    "color_norm_base = make_color_norm(\n",
    "    base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]],   \n",
    "    method=\"percentile\")\n",
    "\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_model_{}_bmals_{}_r_{}_bnels_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                 bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(base_model_predictions_eastMA[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='RdYlGn_r',\n",
    "                         norm=color_norm_base, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The predictive surface of individual BNE gp weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_ensemble_weights = bma_joint_samples['ensemble_weights']\n",
    "ensemble_weights_val = tf.reduce_mean(bma_ensemble_weights, axis=0)\n",
    "\n",
    "weights_dict = {\n",
    "    \"AV\": ensemble_weights_val[:, 0],\n",
    "    \"GS\": ensemble_weights_val[:,1],\n",
    "    \"CACES\": ensemble_weights_val[:,2],\n",
    "}\n",
    "#weights_dict\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(weights_dict.values()),#[2],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_weights_var = np.var(bma_ensemble_weights, axis=0)\n",
    "weights_var_dict = {\n",
    "    \"AV\": ensemble_weights_var[:, 0],\n",
    "    \"GS\": ensemble_weights_var[:,1],\n",
    "    \"CACES\": ensemble_weights_var[:,2],\n",
    "}\n",
    "#weights_dict\n",
    "color_norm_weights_var = make_color_norm(\n",
    "    list(weights_var_dict.values()),#[0],   \n",
    "    method=\"percentile\")\n",
    "# display(ensemble_weights_val,ensemble_weights_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_names = [\"AV\", \"GS\", \"CACES\"]\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'baseweights_{}_bmals_{}_r_{}_bnels_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                 bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(weights_dict[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='viridis',\n",
    "                         norm=color_norm_weights, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         #save_addr='')\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot weights' variance\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'basew_var_{}_bmals_{}_r_{}_bnels_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                 bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(weights_var_dict[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='viridis',\n",
    "                         norm=color_norm_weights_var, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         #save_addr='')\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The predictive surface of Y_mean, residual process, and Y_mean + residual process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BAE\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bae.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bae.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bae.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            '{}_BAE_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name,\n",
    "                                base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "                    save_addr=save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE vo\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bne_vo.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bne_vo.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bne_vo.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            '{}_BNEvo_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name,\n",
    "                                base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                                      save_addr=save_name)\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE v+s\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bne_vs.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bne_vs.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bne_vs.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            '{}_BNEvs_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(name,\n",
    "                                base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "                save_addr=save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.The predictive variance of Y_mean, residual process, and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAE\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bae.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bae.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bae.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            '{}_var_BAE_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name,\n",
    "                                base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE vo\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bne_vo.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bne_vo.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bne_vo.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            '{}_var_BNEvo_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name,\n",
    "                                base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE v+s\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bne_vs.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bne_vs.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bne_vs.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            '{}_var_BNEvs_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name,\n",
    "                                base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWSzplhQKdqt"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_preds_train, base_preds_test, kernel_names = run_base_models(\n",
    "#       X_train1, X_train1, X_test1, Y_train, Y_train, Y_test, num_train_steps=100, debug_mode=False)\n",
    "\n",
    "# d0 = dict(X_base=X_train1,\n",
    "#                    X_train=X_train1,\n",
    "#                    X_test=X_test1,\n",
    "#                    Y_base=Y_train, \n",
    "#                    Y_train=Y_train, \n",
    "#                    Y_test=Y_test, \n",
    "#                    mean_test=Y_test, \n",
    "#                    base_preds_train=base_preds_train, \n",
    "#                    base_preds_test=base_preds_test, \n",
    "#                    base_model_names=kernel_names)\n",
    "\n",
    "# d0 = dict(X_train=X_train1,\n",
    "#                    X_test=X_test1,\n",
    "#                    Y_train=Y_train, \n",
    "#                   # Y_test=Y_test, \n",
    "#                    mean_test=Y_test, \n",
    "#                    base_preds_train=base_preds_train, \n",
    "#                    base_preds_test=base_preds_test, \n",
    "#                    base_model_names=base_model_names)\n",
    "# seed = 1\n",
    "\n",
    "# def run_single2D():\n",
    "#     # Data Generation\n",
    "#     #data_dicts = {}\n",
    "#     data_dicts = d0\n",
    "#     # dict_keys(['X_base', 'X_train', 'X_test', 'Y_base', 'Y_train', 'Y_test', 'mean_test', 'base_preds_train', 'base_preds_test', 'base_model_names'])\n",
    "\n",
    "#     # BMA-mean.\n",
    "#     data_dicts = get_bma_result(d0, bma_config=bma_config) \n",
    "    \n",
    "# #     BMA.\n",
    "# #     Inhere BMA MCMC configs.\n",
    "#     bma_var_config = bne_config.copy()\n",
    "#     bma_var_config['mcmc_initialize_from_map'] = bma_config['mcmc_initialize_from_map']\n",
    "#     gp_weights, data_dicts = get_bne_result(data_dicts, moment_mode='none', \n",
    "#                                       bne_config=bma_var_config) \n",
    "\n",
    "# #     # BAE.\n",
    "# #     data_dicts = get_bne_result(data_dicts, moment_mode='mean', \n",
    "# #                                       bne_config=bne_config) \n",
    "# #     print(data_dicts.keys())\n",
    "\n",
    "# #     # BNE-Variance.\n",
    "# #     data_dicts = get_bne_result(data_dicts, moment_mode='variance', \n",
    "# #                                       bne_config=bne_config) \n",
    "\n",
    "\n",
    "# #     # BNE-Skewness.\n",
    "# #     data_dicts = get_bne_result(data_dicts, moment_mode='skewness', \n",
    "# #                                       bne_config=bne_config) \n",
    "\n",
    "#     return gp_weights, data_dicts\n",
    "\n",
    "# gp_weights1, plt_dict1 = run_single2D()    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_heatmap_2d(eastMA_pred, plt_dict1[\"X_test\"],\n",
    "#                          plt_dict1[\"X_train\"],\n",
    "#                          cmap='RdYlGn_r',\n",
    "#                          norm=None, norm_method=\"percentile\",\n",
    "#                          save_addr='')\n",
    "# posterior_heatmap_2d(eastMA_pred, np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32),\n",
    "#                          np.asarray(training_eastMA_folds[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32),\n",
    "#                          cmap='RdYlGn_r',\n",
    "#                          norm=None, norm_method=\"percentile\",\n",
    "#                          save_addr='')\n",
    "# eastMA_pred_var = np.var(plt_dict1[\"bne_var_samples\"], axis=0)\n",
    "# posterior_heatmap_2d(eastMA_pred_var, plt_dict1[\"X_test\"],\n",
    "#                          plt_dict1[\"X_train\"],\n",
    "#                          cmap='inferno_r',\n",
    "#                          norm=None, norm_method=\"percentile\",\n",
    "#                          save_addr='')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
