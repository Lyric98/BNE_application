{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 15:47:07.355074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 15:47:55.346311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAYcMR698j6J"
   },
   "source": [
    "# Experiment II: 2D Spatial Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AMIJk1OdKIj7"
   },
   "outputs": [],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .5 # @param\n",
    "bma_gp_l2_regularizer = 0.7 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9iyxQiCJKIn7"
   },
   "outputs": [],
   "source": [
    "# BNE parameters.\n",
    "bne_gp_lengthscale = .06 # 5. # @param\n",
    "bne_gp_l2_regularizer = 1. # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training/prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/training_dataset/training_eastMA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_58515/3952871148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_eastMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/training_dataset/training_eastMA.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_eastMA_noMI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_eastMA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraining_eastMA_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/training_dataset/training_eastMA_folds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_model_predictions_eastMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/prediction_dataset/base_model_predictions_eastMA.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_eastMA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_eastMA_folds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model_predictions_eastMA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/training_dataset/training_eastMA.csv'"
     ]
    }
   ],
   "source": [
    "training_eastMA = pd.read_csv('./data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('./data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('./data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "display(training_eastMA.shape, training_eastMA_folds.shape, base_model_predictions_eastMA.shape)\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())\n",
    "\n",
    "\n",
    "training51= pd.read_csv('./data/training_dataset/training51.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "#base_preds_test\n",
    "display(base_preds_train.shape, base_preds_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into configs.\n",
    "from distutils.log import debug\n",
    "\n",
    "\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bma_model_config, map_config, mcmc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_prior, bma_gp_config = bma_dist(X_train1, \n",
    "                                    base_preds_train, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "bma_model_config.update(bma_gp_config)\n",
    "\n",
    "# Check if the model graph is specified correctly.\n",
    "bma_prior.resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_posterior_inference(model_dist: tfd.Distribution, \n",
    "                            Y: tf.Tensor, \n",
    "                            mcmc_config: Dict[str, Any], \n",
    "                            map_config: Optional[Dict[str, Any]] = None, \n",
    "                            model_config: Optional[Dict[str, Any]] = None,\n",
    "                            initialize_from_map: bool = True):\n",
    "  \"\"\"Wrapper function for running MCMC with MAP initialization.\"\"\"\n",
    "  # Defines posterior log likelihood function, and also a \n",
    "  # randomly-sampled initial state from model prior.\n",
    "  nchain = mcmc_config['nchain']\n",
    "  init_state, target_log_prob_fn = prepare_mcmc(model_dist, Y, nchain=nchain)  \n",
    "  \n",
    "  if initialize_from_map:\n",
    "    # Initializes at MAP, shape (num_chains, param_shape_0, param_shape_1).\n",
    "    print('Running MAP:', end='\\t')\n",
    "    init_state = run_map(target_log_prob_fn=target_log_prob_fn, \n",
    "                         gp_config=model_config,\n",
    "                         **map_config)\n",
    "\n",
    "    init_state = tf.stack([init_state] * mcmc_nchain, axis=0)\n",
    "\n",
    "  # Run MCMC, shape (param_shape_0, param_shape_1, num_chains).\n",
    "  print('Running MCMC:', end='\\t')\n",
    "  gp_w_samples, chain_samples, sampler_stat = run_mcmc(init_state=init_state,\n",
    "                             target_log_prob_fn=target_log_prob_fn,\n",
    "                             debug_mode=True,\n",
    "                             **mcmc_config)  \n",
    "  \n",
    "  return gp_w_samples, chain_samples, sampler_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(bma_model_config, map_config,mcmc_config, bma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_gp_w_samples, chain_samples, sampler_stat = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "# Above the debug mode\n",
    "\n",
    "# bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_train, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, None, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chain_samples[:, 8, 1011, 2], c='b', alpha=.3)\n",
    "# plt.title('Traceplot')\n",
    "# plt.plot(bma_gp_w_samples[1][:,9, 127, 1].numpy(), 'b')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean((means_pred - means_true)**2) / np.var(means_true)\n",
    "# mse = tf.reduce_mean((means_train_mcmc-Y_train_mcmc)** 2)/ np.var(Y_train_mcmc)\n",
    "# mse\n",
    "def rmse(y_obs, y_pred):\n",
    "    return np.sqrt(np.mean((y_obs - y_pred) ** 2))\n",
    "bma_mcmc_rmse = rmse(means_train_mcmc, Y_train_mcmc)\n",
    "\n",
    "reg = LinearRegression().fit(X_train1, Y_train)\n",
    "y_pred = reg.predict(X_train1)\n",
    "rmse_lr = mean_squared_error(y_true=Y_train, y_pred=y_pred, squared=False)\n",
    "display(rmse_lr, bma_mcmc_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for BAE/BNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "means_train_mcmc, X_train_mcmc, Y_train_mcmc = make_bma_samples(\n",
    "    X_train1, Y_train, base_preds_train, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_train,\n",
    "    seed=bma_seed, \n",
    "    prepare_mcmc_training=True)\n",
    "\n",
    "# Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "# It is used to generate final examples in `make_bne_samples()`.\n",
    "means_test_mcmc = make_bma_samples(\n",
    "    X_test1, None, base_preds_test, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_test,\n",
    "    seed=bma_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(means_train_mcmc.shape, X_train_mcmc.shape, Y_train_mcmc.shape, means_test_mcmc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Additive Ensemble\n",
    "\n",
    "Given $\\mu(x)$ the posterior of a Bayesian ensemble model, the Bayesian Additive Ensemble is defined as:    \n",
    "\n",
    "$y \\sim N(\\mu(x) + r(x), \\sigma^2)$\n",
    "\n",
    "$r \\sim GaussianProcess(0, k)$\n",
    "\n",
    "The additive ensemble $r(x)$ services two purposes: \n",
    "\n",
    "1. Mitigates systematic bias in model prediction; \n",
    "2. Quantifies the model's epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # BNE GP Configs.\n",
    "# # lengthscale = 1. # @param\n",
    "# # l2_regularizer = 10. # @param\n",
    "\n",
    "# BNE model configs. \n",
    "# If estimate_mean=False, only estimates a constant variance on top of the \n",
    "# original model.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "# # MAP and MCMC configs\n",
    "# map_step_size=0.1 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=1e-2 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "                          l2_regularizer=bne_gp_l2_regularizer))\n",
    "bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "                             variance_prior_mean=variance_prior_mean,\n",
    "                             **bne_gp_config))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bne_prior, bne_model_config, map_config, mcmc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples, chain_samples, sampler_stat = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chain_samples[:, 9, 791, 1], c='b', alpha=.3)\n",
    "# plt.title('Traceplot')\n",
    "# plt.plot(bma_gp_w_samples[1][:,9, 127, 1].numpy(), 'b')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred longitude max and min -69.93 -73.5\n",
      "pred latitude max and min 44.3 40.6\n",
      "train longitude max and min -70.023598 -73.443056\n",
      "train latitude max and min 44.107524 40.74529\n",
      "2011 center and scale:  [-72.185104  42.680347] [3.5699997 3.7000008]\n"
     ]
    }
   ],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n",
    "\n",
    "\n",
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .55 # @param\n",
    "bma_gp_l2_regularizer = .8 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n",
    "\n",
    "\n",
    "# BNE parameters.\n",
    "bne_gp_lengthscale = .05 # 5. # @param\n",
    "bne_gp_l2_regularizer = 1. # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "\n",
    "# ### Read training/prediction data\n",
    "training_eastMA = pd.read_csv('../data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('../data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('../data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())\n",
    "\n",
    "\n",
    "training51= pd.read_csv('../data/training_dataset/training51.csv')\n",
    "\n",
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)\n",
    "\n",
    "\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std,\n",
    "                             #activation='relu',\n",
    "                             activation_func='softmax'))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  3  4  5  6  7  8  9 12 13 14 15 16 17 18 19 20 21 23 24 25 26 27\n",
      " 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50] [ 2 10 11 22 28 29]\n",
      "(45, 2) (6, 2) (45, 1) (6, 1) (45, 3) (6, 3)\n",
      "[0.4849554265795824]\n",
      "[0.4076126206593953]\n",
      "activation function used softmax\n",
      "Running MAP:\t387067.9375...200588.046875...191452.796875...187640.9375...185059.046875...182308.078125...179543.078125...176688.125...173715.828125...170847.859375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7424561381340027\n",
      "activation function used softmax\n",
      "[0.5171763]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 27 28 29 30 31 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49 50] [ 4 26 32 33 45]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905]\n",
      "[0.4076126206593953, 0.6200543960971059]\n",
      "activation function used softmax\n",
      "Running MAP:\t392355.21875...205900.859375...195325.765625...190649.0625...187977.515625...185997.0...184067.875...181466.234375...177930.15625...174416.890625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7656586766242981\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707]\n",
      "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 28 29 30 31 32 33 36 37 38 39 40 42 43 44 45 46 47 48 49 50] [ 7 27 34 35 41]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431]\n",
      "activation function used softmax\n",
      "Running MAP:\t317219.96875...163052.53125...153805.0625...148187.34375...144003.234375...140335.875...137068.015625...134454.984375...132166.6875...129512.6796875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6429890990257263\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 45 47 49 50] [14 18 42 46 48]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652]\n",
      "activation function used softmax\n",
      "Running MAP:\t391966.96875...198909.84375...187883.828125...182753.765625...179903.9375...177828.828125...175544.796875...171269.9375...167153.21875...163528.859375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7463507652282715\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 32 33 34 35 36 37 38 39 40 41 42 44 45 46 47 48 49 50] [15 16 30 31 43]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652, 1.0533299501279885]\n",
      "activation function used softmax\n",
      "Running MAP:\t353075.25...196520.0625...186431.421875...181749.921875...179019.1875...176927.71875...174458.421875...171753.46875...169221.8125...167151.609375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7117614150047302\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989, 0.6218965]\n",
      "[ 0  1  2  3  4  5  6  7  9 10 11 12 14 15 16 17 18 19 21 22 23 24 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49] [ 8 13 20 25 50]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652, 1.0533299501279885, 0.6232392194757831]\n",
      "activation function used softmax\n",
      "Running MAP:\t371586.3125...204015.28125...192844.46875...186507.421875...181289.703125...176695.140625...172778.28125...169000.015625...165209.6875...161978.453125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6327950358390808\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989, 0.6218965, 0.9186188]\n",
      "[ 0  2  3  4  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 38 39 41 42 43 44 45 46 47 48 49 50] [ 1  5 17 37 40]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652, 1.0533299501279885, 0.6232392194757831, 1.171067616797047]\n",
      "activation function used softmax\n",
      "Running MAP:\t350955.78125...197533.046875...187995.53125...183589.515625...180529.375...177732.75...175324.328125...173021.53125...170268.765625...167471.765625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8274880647659302\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989, 0.6218965, 0.9186188, 0.8229612]\n",
      "[ 0  1  2  3  4  5  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 39 40 41 42 43 44 45 46 47 48 49 50] [ 6 12 23 24 38]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449, 0.9174909342215606]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652, 1.0533299501279885, 0.6232392194757831, 1.171067616797047, 0.9480314971038895]\n",
      "activation function used softmax\n",
      "Running MAP:\t356798.875...194338.953125...186224.828125...182575.3125...179726.578125...177008.328125...174499.53125...171921.1875...169379.859375...166948.921875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7338675260543823\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989, 0.6218965, 0.9186188, 0.8229612, 0.63430184]\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 37 38 40 41 42 43 44 45 46 47 48 49 50] [ 9 19 21 36 39]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449, 0.9174909342215606, 0.8068320585424489]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652, 1.0533299501279885, 0.6232392194757831, 1.171067616797047, 0.9480314971038895, 0.6377134671780271]\n",
      "activation function used softmax\n",
      "Running MAP:\t354873.78125...198102.15625...189266.5625...184893.765625...181296.6875...178075.859375...175440.984375...172947.25...170469.953125...168290.6875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8095833659172058\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989, 0.6218965, 0.9186188, 0.8229612, 0.63430184, 0.61640203]\n",
      "[ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 48 50] [ 0  3 44 47 49]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449, 0.9174909342215606, 0.8068320585424489, 1.4073350006838665]\n",
      "[0.4076126206593953, 0.6200543960971059, 1.0748247171900431, 1.0898182194030652, 1.0533299501279885, 0.6232392194757831, 1.171067616797047, 0.9480314971038895, 0.6377134671780271, 1.283049828477898]\n",
      "activation function used softmax\n",
      "Running MAP:\t252062.09375...124024.2578125...118638.109375...115881.1015625...112404.265625...109530.7265625...106958.3671875...104772.4765625...103096.8125...101879.5234375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7721463441848755\n",
      "activation function used softmax\n",
      "[0.5171763, 0.48359707, 1.7311829, 0.8070989, 0.6218965, 0.9186188, 0.8229612, 0.63430184, 0.61640203, 1.9572185]\n",
      "RMSE LR:  0.8535467618362297 0.799006139404427 0.2755349737889978\n",
      "RMSE GAM:  0.8908741532510243 1.000680723615939 0.2789246093619118\n",
      "RMSE BMA:  0.91104543 0.7207004 0.4868859\n",
      "NLL LR:  0.95211065 0.91061574 0.12822385\n",
      "NLL GAM:  1.1779892 1.0415206 0.32692665\n",
      "NLL BMA:  1.0219643 0.93771875 0.2697511\n",
      "Coverage LR:  0.9411764705882353\n",
      "Coverage GAM:  0.9019607843137255\n",
      "Coverage BMA:  0.9411764705882353\n",
      "        lon       lat  raw_error\n",
      "0 -0.342329 -0.423743   0.025233\n",
      "1 -0.240478 -0.305349  -0.135801\n",
      "2  0.130281 -0.287867   0.183149\n",
      "3 -0.115413 -0.155285  -0.041736\n",
      "4 -0.041729 -0.103204   1.012277\n",
      "5  0.308824 -0.094824   0.725093\n",
      "0 -0.282807 -0.407977  -0.469128\n",
      "1  0.108327 -0.113580   0.153135\n",
      "2  0.314667 -0.083304   0.739029\n",
      "3 -0.299440 -0.062794  -0.280227\n",
      "4  0.402546  0.106763   0.548734\n",
      "0  0.392123 -0.364832   2.152607\n",
      "1  0.109464 -0.112539  -0.706872\n",
      "2 -0.299716 -0.061710  -2.823483\n",
      "3  0.340136 -0.055596   1.287842\n",
      "4  0.225480  0.049238   0.470094\n",
      "0 -0.125088 -0.242061   0.804520\n",
      "1  0.230850 -0.226840  -0.131741\n",
      "2 -0.298245  0.056011  -0.262356\n",
      "3  0.203602  0.122193  -1.372866\n",
      "4  0.192932  0.239398   0.799278\n",
      "0  0.216284 -0.235913   0.398374\n",
      "1  0.217835 -0.235436   0.386801\n",
      "2  0.304746 -0.089588  -0.220966\n",
      "3  0.316752 -0.085743  -1.151379\n",
      "4 -0.024433  0.067614  -0.500960\n",
      "0 -0.352367 -0.346265  -0.211296\n",
      "1 -0.125866 -0.253472  -0.070344\n",
      "2  0.605464 -0.190417   0.360929\n",
      "3  0.300038 -0.126642   0.429893\n",
      "4 -0.034845  0.256556   1.963321\n",
      "0 -0.244380 -0.500637   1.305812\n",
      "1 -0.201055 -0.372689  -0.406130\n",
      "2 -0.311527 -0.232163   0.714062\n",
      "3  0.285908  0.004829   0.570587\n",
      "4  0.085849  0.049050   0.825097\n",
      "0 -0.204998 -0.370139   0.018942\n",
      "1  0.284557 -0.268822   0.390826\n",
      "2 -0.113642 -0.154420  -0.688664\n",
      "3 -0.103644 -0.131342   0.909462\n",
      "4  0.207430  0.022083   0.746465\n",
      "0  0.030374 -0.312481  -0.485888\n",
      "1  0.225527 -0.217751  -0.901402\n",
      "2  0.327833 -0.161733   0.522346\n",
      "3  0.230542 -0.014505   0.538898\n",
      "4  0.303310  0.024456   0.536553\n",
      "0 -0.345682 -0.522989   0.364302\n",
      "1 -0.322567 -0.422166  -0.684711\n",
      "2 -0.202995  0.074528   3.533625\n",
      "3 -0.263646  0.126440   2.102952\n",
      "4 -0.223439  0.250732  -1.281820\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, random_state=bma_seed, shuffle=True) \n",
    "\n",
    "rmse_lr = []\n",
    "rmse_gam = []\n",
    "rmse_bma = []\n",
    "\n",
    "nll_lr, nll_gam, nll_bma = [], [], []\n",
    "\n",
    "# initialize a dataframe to store lon, lat and raw error\n",
    "error_df = pd.DataFrame(columns=['lon', 'lat', 'raw_error'])\n",
    "\n",
    "coverage_lr = 0\n",
    "coverage_gam = 0\n",
    "coverage_bma = 0\n",
    "\n",
    "import rpy2\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "#ms = importr('MSGARCH')\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  # convert \"lon\" and \"lat\" in training_eastMA_noMI into scaled X_train1 values\n",
    "  training_eastMA_noMI[\"lon\"] = (training_eastMA_noMI[\"lon\"] - X_centr[0]) / X_scale[0]\n",
    "  training_eastMA_noMI[\"lat\"] = (training_eastMA_noMI[\"lat\"] - X_centr[1]) / X_scale[1]\n",
    "  r_from_pd_df = ro.conversion.py2rpy(training_eastMA_noMI)\n",
    "\n",
    "\n",
    "mgcv  = importr('mgcv')\n",
    "stats = importr('stats')\n",
    "ciTools = importr('ciTools')\n",
    "\n",
    "\n",
    "#ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=10, random_state=bma_seed, shuffle=True) \n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "    #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "    Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "    print(train_index, test_index)\n",
    "    print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape, base_preds_tr.shape, base_preds_te.shape)\n",
    "\n",
    "    r_dat_py = training_eastMA_noMI\n",
    "      \n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        r_tr = ro.conversion.py2rpy(r_dat_py.iloc[train_index])\n",
    "        r_te = ro.conversion.py2rpy(r_dat_py.iloc[test_index])\n",
    "\n",
    "    # Ref: lr\n",
    "    lr_model = stats.lm(ro.Formula('aqs~pred_av+pred_gs+pred_caces'), data=r_tr)\n",
    "    l = ciTools.add_pi(r_te, lr_model)\n",
    "    lr_pred = l[7]\n",
    "    lr_ci_l, lr_ci_u = l[8], l[9]\n",
    "    coverage_lr += np.sum([(Y_te[i] > lr_ci_l[i]) & (Y_te[i] < lr_ci_u[i]) for i in range(len(Y_te))])\n",
    "    rmse_lr.append(rmse(Y_te, np.asanyarray(lr_pred).reshape(-1,1)))\n",
    "    nll_lr.append(nll(Y_te, np.asanyarray(lr_pred).reshape(-1,1)))\n",
    "    print(rmse_lr)\n",
    "\n",
    "    # Ref: GAM\n",
    "    #df = training_eastMA_noMI.iloc[train_index]\n",
    "    gam_model = mgcv.gam(ro.Formula('aqs ~ s(lon, lat, by=pred_av, k=4) + s(lon, lat,by=pred_gs, k=4) +s(lon, lat, by=pred_caces, k=4)'), data=r_tr)\n",
    "    a= ciTools.add_pi(r_te, gam_model)\n",
    "    gam_pred = a[7]\n",
    "    gam_ci_l, gam_ci_u = a[8], a[9]\n",
    "    coverage_gam += np.sum([(Y_te[i] > gam_ci_l[i]) & (Y_te[i] < gam_ci_u[i]) for i in range(len(Y_te))])\n",
    "    rmse_gam.append(rmse(Y_te, np.asanyarray(gam_pred).reshape(-1,1)))\n",
    "    nll_gam.append(nll(Y_te, np.asanyarray(gam_pred).reshape(-1,1)))\n",
    "    print(rmse_gam)\n",
    "\n",
    "    # build model & run MCMC\n",
    "    #fixed_input_tr = tf.ones((X_tr.shape[0], 2), dtype=tf.float32)\n",
    "    bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "                                    base_preds_tr, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "    bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "    bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_tr, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "    #fixed_input_te = tf.ones((X_te.shape[0], 2), dtype=tf.float32)\n",
    "    bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "    y_pred = bma_joint_samples['y']\n",
    "    y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "    raw_error = pd.DataFrame(columns=['lon', 'lat', 'raw_error'])\n",
    "    raw_error[\"lon\"] = X_te[:,0]\n",
    "    raw_error[\"lat\"] = X_te[:,1]\n",
    "    raw_error[\"raw_error\"] = (y_pred - Y_te).numpy().reshape(-1)\n",
    "    error_df = error_df.append(raw_error)\n",
    "\n",
    "    pred_std = calc_prediction_std(y_pred, Y_te)\n",
    "    pred_mean = tf.reduce_mean(y_pred, axis=1)\n",
    "    bma_pi = np.array([(pred_mean - 1.96*pred_std).numpy(), (pred_mean + 1.96*pred_std).numpy()])\n",
    "    coverage_bma += np.sum([(Y_te[i] > bma_pi[0][i]) & (Y_te[i] < bma_pi[1][i]) for i in range(len(Y_te))])\n",
    "    rmse_bma.append(rmse(Y_te, y_pred))\n",
    "    nll_bma.append(nll(Y_te, y_pred))\n",
    "    print(rmse_bma)\n",
    "    # Investigate what examples (e.g., in terms of spatial coordinate) tend to receive high error.\n",
    "\n",
    "  \n",
    "\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.median(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE GAM: \", np.mean(rmse_gam), np.median(rmse_gam), np.std(rmse_gam))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma), np.median(rmse_bma), np.std(rmse_bma))\n",
    "\n",
    "print(\"NLL LR: \", np.mean(nll_lr), np.median(nll_lr), np.std(nll_lr))\n",
    "print(\"NLL GAM: \", np.mean(nll_gam), np.median(nll_gam), np.std(nll_gam))\n",
    "print(\"NLL BMA: \", np.mean(nll_bma), np.median(nll_bma), np.std(nll_bma))\n",
    "\n",
    "print(\"Coverage LR: \", coverage_lr/len(Y_train))\n",
    "print(\"Coverage GAM: \", coverage_gam/len(Y_train))\n",
    "print(\"Coverage BMA: \", coverage_bma/len(Y_train))\n",
    "\n",
    "lr_s = ['', str(np.mean(rmse_lr)), str(np.std(rmse_lr))]\n",
    "gam_s = ['', str(np.mean(rmse_gam)), str(np.std(rmse_gam))]\n",
    "bma_s = [ str(np.mean(rmse_bma)), str(np.std(rmse_bma))]\n",
    "\n",
    "print(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change error_df lon and lat to un normalized values\n",
    "plt_df = error_df.copy()\n",
    "plt_df[\"lon\"] = plt_df[\"lon\"] * X_scale[0] + X_centr[0]\n",
    "plt_df[\"lat\"] = plt_df[\"lat\"] * X_scale[1] + X_centr[1]\n",
    "# abs error\n",
    "plt_df[\"abs_error\"] = abs(plt_df[\"raw_error\"])\n",
    "# plot error_df ordered by abs raw_error\n",
    "plt_df = plt_df.sort_values(by=['abs_error'])\n",
    "plt_df = plt_df.reset_index(drop=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(plt_df[\"lon\"], plt_df[\"lat\"], c=plt_df[\"abs_error\"],\n",
    "            s=abs(plt_df[\"raw_error\"])*100, cmap='inferno_r')\n",
    "cbar = plt.colorbar()\n",
    "# larger points are more error\n",
    "coordinate = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "\n",
    "# limitation x y axis from coordinate\n",
    "plt.xlim(min(coordinate[:,0]), max(coordinate[:,0]))\n",
    "plt.ylim(min(coordinate[:,1]), max(coordinate[:,1]))\n",
    "\n",
    "# plt_df.plot.scatter(x='lon', y='lat', c='abs_error', s=abs(plt_df[\"raw_error\"])*100,\n",
    "#                       colormap='inferno_r', figsize=(10, 8))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mon_id</th>\n",
       "      <th>aqs</th>\n",
       "      <th>pred_av</th>\n",
       "      <th>pred_gs</th>\n",
       "      <th>pred_caces</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rhode Island-Providence-0026-88101-1</td>\n",
       "      <td>9.955856</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.603328</td>\n",
       "      <td>9.027592</td>\n",
       "      <td>0.225528</td>\n",
       "      <td>-0.217751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Massachusetts-Dukes-0001-88502-1</td>\n",
       "      <td>6.346957</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9.257568</td>\n",
       "      <td>8.499855</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>-0.364832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Vermont-Rutland-0002-88101-1</td>\n",
       "      <td>10.387156</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.423113</td>\n",
       "      <td>9.105349</td>\n",
       "      <td>-0.223438</td>\n",
       "      <td>0.250732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York-Suffolk-0009-88502-3</td>\n",
       "      <td>8.396442</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.200440</td>\n",
       "      <td>10.367752</td>\n",
       "      <td>-0.244380</td>\n",
       "      <td>-0.500637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>New Hampshire-Merrimack-1006-88101-1</td>\n",
       "      <td>8.909402</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.922614</td>\n",
       "      <td>7.537278</td>\n",
       "      <td>0.203602</td>\n",
       "      <td>0.122193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Vermont-Bennington-8001-88502-1</td>\n",
       "      <td>3.886408</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8.559377</td>\n",
       "      <td>5.990102</td>\n",
       "      <td>-0.263647</td>\n",
       "      <td>0.126440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Massachusetts-Suffolk-0043-88101-1</td>\n",
       "      <td>10.250689</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.050020</td>\n",
       "      <td>8.512729</td>\n",
       "      <td>0.316752</td>\n",
       "      <td>-0.085743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Massachusetts-Berkshire-0006-88502-3</td>\n",
       "      <td>11.023407</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.156252</td>\n",
       "      <td>8.812862</td>\n",
       "      <td>-0.299716</td>\n",
       "      <td>-0.061711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont-Windham-9000-88502-1</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.406383</td>\n",
       "      <td>5.113718</td>\n",
       "      <td>-0.202996</td>\n",
       "      <td>0.074528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mon_id        aqs  pred_av    pred_gs  \\\n",
       "19  Rhode Island-Providence-0026-88101-1   9.955856      9.5   9.603328   \n",
       "7       Massachusetts-Dukes-0001-88502-1   6.346957      5.4   9.257568   \n",
       "49          Vermont-Rutland-0002-88101-1  10.387156      8.6   9.423113   \n",
       "1          New York-Suffolk-0009-88502-3   8.396442      8.6  11.200440   \n",
       "46  New Hampshire-Merrimack-1006-88101-1   8.909402      8.9   8.922614   \n",
       "47       Vermont-Bennington-8001-88502-1   3.886408      4.1   8.559377   \n",
       "31    Massachusetts-Suffolk-0043-88101-1  10.250689      9.2   8.050020   \n",
       "34  Massachusetts-Berkshire-0006-88502-3  11.023407      8.2   8.156252   \n",
       "44          Vermont-Windham-9000-88502-1   1.580000      4.2   8.406383   \n",
       "\n",
       "    pred_caces       lon       lat  \n",
       "19    9.027592  0.225528 -0.217751  \n",
       "7     8.499855  0.392123 -0.364832  \n",
       "49    9.105349 -0.223438  0.250732  \n",
       "1    10.367752 -0.244380 -0.500637  \n",
       "46    7.537278  0.203602  0.122193  \n",
       "47    5.990102 -0.263647  0.126440  \n",
       "31    8.512729  0.316752 -0.085743  \n",
       "34    8.812862 -0.299716 -0.061711  \n",
       "44    5.113718 -0.202996  0.074528  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the worst predictions and find them in the original dataset \"training_eastMA_noMI\"\n",
    "# change error_df lon and lat to un normalized values\n",
    "plt_df5 = error_df.copy()\n",
    "\n",
    "plt_df5[\"abs_error\"] = abs(plt_df5[\"raw_error\"])\n",
    "# plot error_df ordered by abs raw_error\n",
    "plt_df5 = plt_df5.sort_values(by=['abs_error'])\n",
    "plt_df5 = plt_df5.reset_index(drop=True)\n",
    "\n",
    "df6 = plt_df5.tail(10).round(5)\n",
    "\n",
    "df6[\"lon\"] = df6[\"lon\"].astype(float).round(5)\n",
    "# show them in the original dataset\n",
    "training_eastMA_noMI.loc[training_eastMA_noMI['lon'].round(\n",
    "    5) == df6[\"lon\"].iloc[1]]\n",
    "df5 = pd.DataFrame(columns=training_eastMA_noMI.columns)\n",
    "for i in range(len(df6)):\n",
    "    df5 = df5.append(\n",
    "    training_eastMA_noMI.loc[training_eastMA_noMI['lon'].round(\n",
    "        5) == df6[\"lon\"].iloc[i]])\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>raw_error</th>\n",
       "      <th>abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.225527</td>\n",
       "      <td>-0.217751</td>\n",
       "      <td>-1.098531</td>\n",
       "      <td>1.098531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.392123</td>\n",
       "      <td>-0.364832</td>\n",
       "      <td>1.315563</td>\n",
       "      <td>1.315563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.223439</td>\n",
       "      <td>0.250732</td>\n",
       "      <td>-1.385115</td>\n",
       "      <td>1.385115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.244380</td>\n",
       "      <td>-0.500637</td>\n",
       "      <td>1.437589</td>\n",
       "      <td>1.437589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.034845</td>\n",
       "      <td>0.256556</td>\n",
       "      <td>1.558877</td>\n",
       "      <td>1.558877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.203602</td>\n",
       "      <td>0.122193</td>\n",
       "      <td>-1.637776</td>\n",
       "      <td>1.637776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.263646</td>\n",
       "      <td>0.126440</td>\n",
       "      <td>1.930435</td>\n",
       "      <td>1.930435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.316752</td>\n",
       "      <td>-0.085743</td>\n",
       "      <td>-1.988200</td>\n",
       "      <td>1.988200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.299716</td>\n",
       "      <td>-0.061710</td>\n",
       "      <td>-2.923090</td>\n",
       "      <td>2.923090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.202995</td>\n",
       "      <td>0.074528</td>\n",
       "      <td>3.377705</td>\n",
       "      <td>3.377705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lon       lat  raw_error  abs_error\n",
       "41  0.225527 -0.217751  -1.098531   1.098531\n",
       "42  0.392123 -0.364832   1.315563   1.315563\n",
       "43 -0.223439  0.250732  -1.385115   1.385115\n",
       "44 -0.244380 -0.500637   1.437589   1.437589\n",
       "45 -0.034845  0.256556   1.558877   1.558877\n",
       "46  0.203602  0.122193  -1.637776   1.637776\n",
       "47 -0.263646  0.126440   1.930435   1.930435\n",
       "48  0.316752 -0.085743  -1.988200   1.988200\n",
       "49 -0.299716 -0.061710  -2.923090   2.923090\n",
       "50 -0.202995  0.074528   3.377705   3.377705"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt_df5.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 28 29 30 31 32 33 36 37 38 39 40 42 43 44 45 46 47 48 49 50] [ 7 27 34 35 41]\n",
      "activation function used softmax\n",
      "Running MAP:\t310209.96875...162597.65625...153542.28125...147906.484375...143686.75...140029.796875...136795.78125...134188.8125...131829.59375...129098.75...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6239896416664124\n",
      "activation function used softmax\n",
      "true value [[ 6.3469567  9.01      11.023407   7.4215517  6.447826 ]]\n",
      "BMA prediction [[8.499564  8.303128  8.199918  8.709384  6.8914576]]\n",
      "LR prediction [1] 6.937434 8.265798 8.475899 8.166726 6.417884\n",
      "\n",
      "GAM prediction [1] 5.753456 8.372504 9.240129 8.482532 5.604121\n",
      "\n",
      "pred_std tf.Tensor(1.9323416, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([8.499564  8.303128  8.199918  8.709384  6.8914576], shape=(5,), dtype=float32)\n",
      "[[ 4.7121744  4.5157385  4.412528   4.921994   3.104068 ]\n",
      " [12.286954  12.090518  11.987308  12.496774  10.678847 ]]\n",
      "coverage 5\n",
      "[ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 48 50] [ 0  3 44 47 49]\n",
      "activation function used softmax\n",
      "Running MAP:\t254995.9375...123988.515625...118661.484375...116087.40625...112745.6796875...109849.9140625...107222.9453125...104959.90625...103225.625...101968.2265625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7696617841720581\n",
      "activation function used softmax\n",
      "true value [[ 8.835652   9.485      1.58       3.8864079 10.387156 ]]\n",
      "BMA prediction [[9.199929 8.800289 5.113625 5.98936  9.105335]]\n",
      "LR prediction [1] 9.139448 9.068365 4.094175 4.718711 8.767501\n",
      "\n",
      "GAM prediction [1] 9.294020 9.288111 3.922369 5.270176 9.625110\n",
      "\n",
      "pred_std tf.Tensor(1.9936367, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.199929 8.800289 5.113625 5.98936  9.105335], shape=(5,), dtype=float32)\n",
      "[[ 5.2924013  4.892761   1.2060969  2.0818317  5.1978073]\n",
      " [13.107457  12.707817   9.021153   9.896888  13.012863 ]]\n",
      "coverage 10\n",
      "[1.729786, 1.9572176]\n"
     ]
    }
   ],
   "source": [
    "# index the third/ten fold of the data\n",
    "rmse_bma_check = []\n",
    "coverage_bma_check = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train1)):\n",
    "    if i == 2 or i == 9:\n",
    "        X_tr, X_te = X_train1[train_index], X_train1[test_index]\n",
    "        Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "        \n",
    "        base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "        print(train_index, test_index)\n",
    "        # build model & run MCMC\n",
    "        #fixed_input_tr = tf.ones((X_tr.shape[0], 2), dtype=tf.float32)\n",
    "        r_dat_py = training_eastMA_noMI\n",
    "      \n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            r_tr = ro.conversion.py2rpy(r_dat_py.iloc[train_index])\n",
    "            r_te = ro.conversion.py2rpy(r_dat_py.iloc[test_index])\n",
    "\n",
    "        # Ref: lr\n",
    "        lr_model = stats.lm(ro.Formula('aqs~pred_av+pred_gs+pred_caces'), data=r_tr)\n",
    "        l = ciTools.add_pi(r_te, lr_model)\n",
    "        lr_pred = l[7]\n",
    "\n",
    "\n",
    "         # Ref: GAM\n",
    "        #df = training_eastMA_noMI.iloc[train_index]\n",
    "        gam_model = mgcv.gam(ro.Formula('aqs ~ s(lon, lat, by=pred_av, k=4) + s(lon, lat,by=pred_gs, k=4) +s(lon, lat, by=pred_caces, k=4)'), data=r_tr)\n",
    "        a= ciTools.add_pi(r_te, gam_model)\n",
    "        gam_pred = a[7]\n",
    "\n",
    "\n",
    "        bma_prior, bma_gp_config = bma_dist(X_tr,\n",
    "                                        base_preds_tr,\n",
    "                                        **bma_model_config)\n",
    "\n",
    "        bma_model_config.update(bma_gp_config)\n",
    "\n",
    "        bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior,\n",
    "                                               model_config=bma_model_config,\n",
    "                                               Y=Y_tr,\n",
    "                                               map_config=map_config,\n",
    "                                               mcmc_config=mcmc_config)\n",
    "\n",
    "        #fixed_input_te = tf.ones((X_te.shape[0], 2), dtype=tf.float32)\n",
    "        bma_joint_samples = make_bma_samples(X_te, None, base_preds_te,\n",
    "                                         bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                         bma_model_config=bma_model_config,\n",
    "                                         n_samples=bma_n_samples_eval,\n",
    "                                         seed=bne_seed,\n",
    "                                         y_samples_only=False)\n",
    "        y_pred = bma_joint_samples['y']\n",
    "        y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "        print(\"true value\", Y_te.T)\n",
    "        print(\"BMA prediction\", y_pred.numpy().T)\n",
    "        print(\"LR prediction\", lr_pred)\n",
    "        print(\"GAM prediction\", gam_pred)\n",
    "        pred_std = calc_prediction_std(y_pred, Y_te)\n",
    "        print(\"pred_std\", pred_std)\n",
    "        pred_mean = tf.reduce_mean(y_pred, axis=1)\n",
    "        print(\"pred_mean\",pred_mean)\n",
    "        bma_pi = np.array([(pred_mean - 1.96*pred_std).numpy(),\n",
    "                      (pred_mean + 1.96*pred_std).numpy()])\n",
    "        print(bma_pi)\n",
    "        coverage_bma_check += np.sum([(Y_te[i] > bma_pi[0][i]) &\n",
    "                           (Y_te[i] < bma_pi[1][i]) for i in range(len(Y_te))])\n",
    "        print(\"coverage\", coverage_bma_check)\n",
    "        rmse_bma_check.append(rmse(Y_te, y_pred))\n",
    "    \n",
    "print(rmse_bma_check)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot out distribution of RMSE error to understand why median RMSE << mean RMSE.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(rmse_lr, bins=20, alpha=0.5, label='LR')\n",
    "plt.hist(rmse_gam, bins=20, alpha=0.5, label='GAM')\n",
    "plt.hist(rmse_bma, bins=20, alpha=0.5, label='BMA')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('RMSE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of RMSE')\n",
    "plt.show()\n",
    "# Plot out distribution of NLL error to understand why median NLL << mean NLL.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(nll_lr, bins=20, alpha=0.5, label='LR')\n",
    "plt.hist(nll_gam, bins=20, alpha=0.5, label='GAM')\n",
    "plt.hist(nll_bma, bins=20, alpha=0.5, label='BMA')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of NLL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred longitude max and min -69.93 -73.5\n",
      "pred latitude max and min 44.3 40.6\n",
      "train longitude max and min -70.023598 -73.443056\n",
      "train latitude max and min 44.107524 40.74529\n",
      "2011 center and scale:  [-72.185104  42.680347] [3.5699997 3.7000008]\n",
      "{'lengthscale': 0.55, 'l2_regularizer': 0.3, 'hidden_units': 128, 'y_noise_std': 0.01, 'activation_func': 'softmax'}\n",
      "{'gp_lengthscale': 0.55, 'gp_l2_regularizer': 0.3, 'y_noise_std': 0.01, 'map_step_size': 0.0005, 'map_num_steps': 10000, 'mcmc_step_size': 0.0001, 'mcmc_num_steps': 1000, 'mcmc_initialize_from_map': False, 'n_samples_eval': 250, 'n_samples_train': 100, 'n_samples_test': 250, 'seed': 0}\n",
      "{'gp_lengthscale': 7.5, 'gp_l2_regularizer': 10, 'variance_prior_mean': -2.5, 'skewness_prior_mean': -2.5, 'map_step_size': 0.0005, 'map_num_steps': 10000, 'mcmc_step_size': 0.0001, 'mcmc_num_steps': 1000, 'mcmc_nchain': 10, 'mcmc_burnin': 2500, 'mcmc_initialize_from_map': True, 'seed': 0}\n"
     ]
    }
   ],
   "source": [
    "# use BAE as the 1st step\n",
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n",
    "\n",
    "\n",
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .55 # @param\n",
    "bma_gp_l2_regularizer = .3 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n",
    "\n",
    "\n",
    "# BNE parameters.\n",
    "bne_gp_lengthscale = .05 # 5. # @param\n",
    "bne_gp_l2_regularizer = 1. # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "\n",
    "# ### Read training/prediction data\n",
    "training_eastMA = pd.read_csv('../data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('../data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('../data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())\n",
    "\n",
    "\n",
    "training51= pd.read_csv('../data/training_dataset/training51.csv')\n",
    "\n",
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)\n",
    "\n",
    "\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std,\n",
    "                             #activation='relu',\n",
    "                             activation_func='softmax'))\n",
    "print(bma_model_config)\n",
    "\n",
    "bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "                gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "                y_noise_std=y_noise_std,\n",
    "                map_step_size=map_step_size,\n",
    "                map_num_steps=map_num_steps,\n",
    "                mcmc_step_size=mcmc_step_size,\n",
    "                mcmc_num_steps=mcmc_num_steps,\n",
    "                mcmc_initialize_from_map=False,\n",
    "                n_samples_eval=bma_n_samples_eval,\n",
    "                n_samples_train=bma_n_samples_train,\n",
    "                n_samples_test=bma_n_samples_test,\n",
    "                seed=bma_seed)\n",
    "print(bma_config)\n",
    "\n",
    "\n",
    "\n",
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 7.5  # 5. # @param\n",
    "bne_gp_l2_regularizer = 10  # 15 # @param\n",
    "bne_variance_prior_mean = -2.5  # @param\n",
    "bne_skewness_prior_mean = -2.5  # @param\n",
    "bne_seed = 0  # @param\n",
    "bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "                  gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "                  variance_prior_mean=bne_variance_prior_mean,\n",
    "                  skewness_prior_mean=bne_skewness_prior_mean,\n",
    "                  map_step_size=map_step_size,\n",
    "                  map_num_steps=map_num_steps,\n",
    "                  mcmc_step_size=mcmc_step_size,\n",
    "                  mcmc_num_steps=mcmc_num_steps,\n",
    "                  mcmc_nchain=mcmc_nchain,\n",
    "                  mcmc_burnin=mcmc_burnin,\n",
    "                  mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "                  seed=bne_seed)\n",
    "\n",
    "print(bne_config)\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  3  4  5  6  7  8  9 12 13 14 15 16 17 18 19 20 21 23 24 25 26 27\n",
      " 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50] [ 2 10 11 22 28 29]\n",
      "(45, 2) (6, 2) (45, 1) (6, 1) (45, 3) (6, 3)\n",
      "[0.4849554265795824]\n",
      "[0.40761262064273013]\n",
      "activation function used softmax\n",
      "Running MAP:\t360300.6875...199465.75...191216.0...187648.515625...184917.0625...182011.34375...179152.0625...176142.75...173089.359375...170184.375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7667247653007507\n",
      "activation function used softmax\n",
      "BMA prediction [[10.000861   9.700449   6.5291615  9.199209   6.0986676  9.199632 ]]\n",
      "LR prediction [1] 10.122534  9.868970  5.900925  9.721513  5.350043  9.428457\n",
      "\n",
      "GAM prediction [1] 10.211692  9.819234  5.673587  9.639126  5.343896  9.012283\n",
      "\n",
      "pred_std tf.Tensor(0.46708164, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([10.000861   9.700449   6.5291615  9.199209   6.0986676  9.199632 ], shape=(6,), dtype=float32)\n",
      "[[ 9.0853815  8.784969   5.6136813  8.28373    5.1831875  8.284152 ]\n",
      " [10.916341  10.615929   7.4446416 10.114689   7.0141478 10.115111 ]]\n",
      "[[9.97563  ]\n",
      " [9.837391 ]\n",
      " [6.332692 ]\n",
      " [9.2525   ]\n",
      " [5.0865545]\n",
      " [8.473109 ]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.7530794143676758\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[10.141383 ]\n",
      " [ 9.808298 ]\n",
      " [ 6.4575377]\n",
      " [ 9.202971 ]\n",
      " [ 6.0986686]\n",
      " [ 9.171652 ]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.7705551981925964\n",
      "[[10.125133 ]\n",
      " [ 9.729334 ]\n",
      " [ 6.505002 ]\n",
      " [ 9.155392 ]\n",
      " [ 5.9703245]\n",
      " [ 9.110973 ]]\n",
      "Running MAP:\t311422.15625...126605.1015625...67296.890625...39616.625...24813.138671875...16361.1982421875...11425.6552734375...8573.3212890625...6996.1171875...6197.986328125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6578803658485413\n",
      "[[10.02548  ]\n",
      " [ 9.631155 ]\n",
      " [ 6.3951507]\n",
      " [ 9.051133 ]\n",
      " [ 5.8625216]\n",
      " [ 8.994725 ]]\n",
      "rmse:\n",
      "[0.5096889] [0.45845175] [0.40076512]\n",
      "nll:\n",
      "[1.377998] [1.2914319] [1.0085629]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 27 28 29 30 31 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49 50] [ 4 26 32 33 45]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905]\n",
      "[0.40761262064273013, 0.6200543961089939]\n",
      "activation function used softmax\n",
      "Running MAP:\t369515.46875...205216.5625...195158.296875...190619.78125...187999.625...185981.328125...183914.75...180968.453125...177336.109375...173824.484375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6861461400985718\n",
      "activation function used softmax\n",
      "BMA prediction [[9.49993   8.752252  9.3988905 8.799258  7.0631   ]]\n",
      "LR prediction [1] 9.580717 8.810792 9.706891 9.052585 6.818999\n",
      "\n",
      "GAM prediction [1]  9.746925  8.858188  9.322717 10.035582  7.173532\n",
      "\n",
      "pred_std tf.Tensor(0.5211263, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.49993   8.752252  9.3988905 8.799258  7.0631   ], shape=(5,), dtype=float32)\n",
      "[[ 8.478523   7.730844   8.377483   7.7778506  6.0416923]\n",
      " [10.5213375  9.773659  10.420298   9.820665   8.084507 ]]\n",
      "[[9.969748]\n",
      " [8.599174]\n",
      " [8.657759]\n",
      " [9.079487]\n",
      " [6.503226]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.7574897408485413\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[9.580795 ]\n",
      " [8.752242 ]\n",
      " [9.35231  ]\n",
      " [8.837875 ]\n",
      " [7.1985545]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8139399290084839\n",
      "[[9.525076]\n",
      " [8.720247]\n",
      " [9.261722]\n",
      " [8.71865 ]\n",
      " [7.18416 ]]\n",
      "Running MAP:\t245083.25...103881.765625...55279.41796875...32669.1484375...20659.3671875...13883.80078125...10000.5517578125...7819.70458984375...6666.74267578125...6124.99755859375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6562026143074036\n",
      "[[9.417117]\n",
      " [8.60362 ]\n",
      " [9.142086]\n",
      " [8.608973]\n",
      " [7.055573]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843] [0.45845175, 0.48395] [0.40076512, 0.46183637]\n",
      "nll:\n",
      "[1.377998, 0.92900085] [1.2914319, 0.85249555] [1.0085629, 0.80004853]\n",
      "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 28 29 30 31 32 33 36 37 38 39 40 42 43 44 45 46 47 48 49 50] [ 7 27 34 35 41]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942]\n",
      "activation function used softmax\n",
      "Running MAP:\t287236.625...161412.9375...152686.359375...147315.984375...143286.8125...139579.796875...136433.8125...133953.90625...131659.75...128819.8359375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6751996278762817\n",
      "activation function used softmax\n",
      "BMA prediction [[8.499564  8.30312   8.199912  8.709611  7.0067124]]\n",
      "LR prediction [1] 6.937434 8.265798 8.475899 8.166726 6.417884\n",
      "\n",
      "GAM prediction [1] 5.753456 8.372504 9.240129 8.482532 5.604121\n",
      "\n",
      "pred_std tf.Tensor(1.9386172, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([8.499564  8.30312   8.199912  8.709611  7.0067124], shape=(5,), dtype=float32)\n",
      "[[ 4.6998744  4.50343    4.4002223  4.909921   3.2070227]\n",
      " [12.299253  12.10281   11.999601  12.5093    10.806402 ]]\n",
      "[[ 6.3469567]\n",
      " [ 9.01     ]\n",
      " [11.023407 ]\n",
      " [ 7.4215517]\n",
      " [ 6.447826 ]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.6615779995918274\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[7.8942695]\n",
      " [8.303245 ]\n",
      " [8.366608 ]\n",
      " [8.66652  ]\n",
      " [6.753341 ]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.7211170196533203\n",
      "[[7.84528 ]\n",
      " [8.273523]\n",
      " [8.285954]\n",
      " [8.562851]\n",
      " [6.742785]]\n",
      "Running MAP:\t247382.546875...101912.9609375...53874.0234375...31573.884765625...19733.638671875...13045.982421875...9209.9208984375...7057.2646484375...5921.87158203125...5390.376953125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7854219079017639\n",
      "[[7.66252 ]\n",
      " [8.087835]\n",
      " [8.100317]\n",
      " [8.376203]\n",
      " [6.54458 ]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623] [0.45845175, 0.48395, 1.5277816] [0.40076512, 0.46183637, 1.5521771]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757] [1.2914319, 0.85249555, 0.804008] [1.0085629, 0.80004853, 0.83011866]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 45 47 49 50] [14 18 42 46 48]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746]\n",
      "activation function used softmax\n",
      "Running MAP:\t364435.34375...196869.625...186909.984375...182314.515625...179641.90625...177489.296875...174368.4375...170095.90625...166128.625...162536.703125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7601441740989685\n",
      "activation function used softmax\n",
      "BMA prediction [[9.606868  8.561643  6.7999077 7.536536  6.790506 ]]\n",
      "LR prediction [1] 9.729070 8.879319 6.009034 7.538783 6.161012\n",
      "\n",
      "GAM prediction [1] 9.631025 8.644170 5.769265 7.114167 6.574314\n",
      "\n",
      "pred_std tf.Tensor(0.90252686, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.606868  8.561643  6.7999077 7.536536  6.790506 ], shape=(5,), dtype=float32)\n",
      "[[ 7.837915   6.79269    5.030955   5.7675834  5.021553 ]\n",
      " [11.37582   10.330595   8.56886    9.305489   8.559459 ]]\n",
      "[[8.803155]\n",
      " [8.728161]\n",
      " [7.062264]\n",
      " [8.909402]\n",
      " [5.991228]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.6183916926383972\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[9.490395 ]\n",
      " [8.864169 ]\n",
      " [6.74041  ]\n",
      " [7.5366163]\n",
      " [6.825264 ]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8147476315498352\n",
      "[[9.435921 ]\n",
      " [8.832998 ]\n",
      " [6.652049 ]\n",
      " [7.420287 ]\n",
      " [6.8112583]]\n",
      "Running MAP:\t231911.859375...97127.390625...51646.46875...30594.064453125...19404.46484375...13087.04296875...9473.837890625...7458.548828125...6407.7021484375...5925.96875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6609734892845154\n",
      "[[9.301277 ]\n",
      " [8.6912155]\n",
      " [6.5176854]\n",
      " [7.271626 ]\n",
      " [6.6529098]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115] [0.45845175, 0.48395, 1.5277816, 0.83301526] [0.40076512, 0.46183637, 1.5521771, 0.8562931]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704] [1.2914319, 0.85249555, 0.804008, 0.8054207] [1.0085629, 0.80004853, 0.83011866, 0.85218525]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 32 33 34 35 36 37 38 39 40 41 42 44 45 46 47 48 49 50] [15 16 30 31 43]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746, 1.0533299501118047]\n",
      "activation function used softmax\n",
      "Running MAP:\t382416.6875...197796.828125...187259.46875...182458.5...179661.9375...177553.359375...175176.703125...172458.515625...169859.9375...167652.6875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6811429262161255\n",
      "activation function used softmax\n",
      "BMA prediction [[9.092606 9.093918 9.193438 9.190348 8.397318]]\n",
      "LR prediction [1] 8.762108 8.762108 9.174723 8.709885 8.068356\n",
      "\n",
      "GAM prediction [1] 8.608835 8.608333 8.629882 8.368169 7.697024\n",
      "\n",
      "pred_std tf.Tensor(0.64423776, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.092606 9.093918 9.193438 9.190348 8.397318], shape=(5,), dtype=float32)\n",
      "[[ 7.8299    7.831212  7.930732  7.927642  7.134612]\n",
      " [10.355311 10.356624 10.456143 10.453053  9.660024]]\n",
      "[[ 8.640988]\n",
      " [ 8.654546]\n",
      " [ 9.376471]\n",
      " [10.250689]\n",
      " [ 8.898305]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.6674602627754211\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[8.90076 ]\n",
      " [8.901332]\n",
      " [9.046666]\n",
      " [8.585136]\n",
      " [8.421533]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8142477869987488\n",
      "[[8.845397 ]\n",
      " [8.8695345]\n",
      " [8.956658 ]\n",
      " [8.466688 ]\n",
      " [8.407229 ]]\n",
      "Running MAP:\t183256.0625...73635.6640625...39193.26171875...23437.353515625...15190.673828125...10622.9609375...8083.5654296875...6731.89599609375...6081.72900390625...5823.0439453125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6634393334388733\n",
      "[[8.643009]\n",
      " [8.668998]\n",
      " [8.751633]\n",
      " [8.262488]\n",
      " [8.202836]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194] [0.45845175, 0.48395, 1.5277816, 0.83301526, 0.85884315] [0.40076512, 0.46183637, 1.5521771, 0.8562931, 0.9825734]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704, 1.0506878] [1.2914319, 0.85249555, 0.804008, 0.8054207, 1.1123323] [1.0085629, 0.80004853, 0.83011866, 0.85218525, 1.4519392]\n",
      "[ 0  1  2  3  4  5  6  7  9 10 11 12 14 15 16 17 18 19 21 22 23 24 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49] [ 8 13 20 25 50]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746, 1.0533299501118047, 0.6232392194797506]\n",
      "activation function used softmax\n",
      "Running MAP:\t364038.84375...202289.390625...191935.15625...186027.203125...181066.75...176699.53125...172965.875...169207.421875...165295.796875...161981.6875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7593435645103455\n",
      "activation function used softmax\n",
      "BMA prediction [[9.3159485 9.29053   5.9008074 7.8917036 8.599988 ]]\n",
      "LR prediction [1] 9.253801 9.675908 4.380024 7.655140 7.645940\n",
      "\n",
      "GAM prediction [1] 9.300968 9.357386 5.450329 7.711961 7.988650\n",
      "\n",
      "pred_std tf.Tensor(0.863703, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.3159485 9.29053   5.9008074 7.8917036 8.599988 ], shape=(5,), dtype=float32)\n",
      "[[ 7.6230907  7.5976725  4.2079496  6.198846   6.9071302]\n",
      " [11.008806  10.983388   7.593665   9.584561  10.292846 ]]\n",
      "[[9.52807  ]\n",
      " [9.362832 ]\n",
      " [5.460345 ]\n",
      " [7.4618163]\n",
      " [6.636667 ]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.7112334966659546\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[9.494084 ]\n",
      " [9.295187 ]\n",
      " [5.5064383]\n",
      " [7.911026 ]\n",
      " [8.335051 ]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8170527219772339\n",
      "[[9.440522 ]\n",
      " [9.264458 ]\n",
      " [5.4195347]\n",
      " [7.796583 ]\n",
      " [8.321601 ]]\n",
      "Running MAP:\t173195.34375...71312.2890625...37995.03515625...22677.62109375...14672.818359375...10265.822265625...7837.95947265625...6560.779296875...5955.47021484375...5719.904296875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.670025646686554\n",
      "[[9.330696 ]\n",
      " [9.1504   ]\n",
      " [5.2898016]\n",
      " [7.673419 ]\n",
      " [8.195544 ]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194, 0.7866578] [0.45845175, 0.48395, 1.5277816, 0.83301526, 0.85884315, 0.7707243] [0.40076512, 0.46183637, 1.5521771, 0.8562931, 0.9825734, 0.7194503]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704, 1.0506878, 1.1156065] [1.2914319, 0.85249555, 0.804008, 0.8054207, 1.1123323, 1.0210264] [1.0085629, 0.80004853, 0.83011866, 0.85218525, 1.4519392, 0.89832944]\n",
      "[ 0  2  3  4  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 38 39 41 42 43 44 45 46 47 48 49 50] [ 1  5 17 37 40]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746, 1.0533299501118047, 0.6232392194797506, 1.1710676167815903]\n",
      "activation function used softmax\n",
      "Running MAP:\t335763.34375...197563.734375...188179.640625...183694.890625...180471.078125...177709.671875...175334.28125...172900.421875...169952.40625...167124.140625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7615187764167786\n",
      "activation function used softmax\n",
      "BMA prediction [[9.472174  9.626604  6.4385133 8.737983  5.7447767]]\n",
      "LR prediction [1] 9.861479 9.829604 5.907082 8.747453 4.319140\n",
      "\n",
      "GAM prediction [1] 10.588808  9.398916  6.534696  8.884988  4.260290\n",
      "\n",
      "pred_std tf.Tensor(0.57317585, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.472174  9.626604  6.4385133 8.737983  5.7447767], shape=(5,), dtype=float32)\n",
      "[[ 8.348749   8.50318    5.3150887  7.614558   4.621352 ]\n",
      " [10.595598  10.750029   7.561938   9.861407   6.8682013]]\n",
      "[[ 8.396441]\n",
      " [10.035838]\n",
      " [ 5.682759]\n",
      " [ 8.189075]\n",
      " [ 4.919658]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.7724781632423401\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[9.989731 ]\n",
      " [9.625831 ]\n",
      " [6.5106516]\n",
      " [8.748166 ]\n",
      " [5.7249603]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8172471523284912\n",
      "[[9.936379 ]\n",
      " [9.595226 ]\n",
      " [6.424084 ]\n",
      " [8.634173 ]\n",
      " [5.7115607]]\n",
      "Running MAP:\t427372.1875...172998.390625...91823.2421875...53807.05859375...33345.7578125...21534.064453125...14514.392578125...10343.33984375...7931.43603515625...6617.9677734375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6700566411018372\n",
      "[[9.83403  ]\n",
      " [9.4921055]\n",
      " [6.3229427]\n",
      " [8.515601 ]\n",
      " [5.5897193]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194, 0.7866578, 0.9330785] [0.45845175, 0.48395, 1.5277816, 0.83301526, 0.85884315, 0.7707243, 0.88773113] [0.40076512, 0.46183637, 1.5521771, 0.8562931, 0.9825734, 0.7194503, 0.81581163]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704, 1.0506878, 1.1156065, 1.6789109] [1.2914319, 0.85249555, 0.804008, 0.8054207, 1.1123323, 1.0210264, 1.5407387] [1.0085629, 0.80004853, 0.83011866, 0.85218525, 1.4519392, 0.89832944, 1.3005803]\n",
      "[ 0  1  2  3  4  5  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 39 40 41 42 43 44 45 46 47 48 49 50] [ 6 12 23 24 38]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449, 0.9174909342215606]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746, 1.0533299501118047, 0.6232392194797506, 1.1710676167815903, 0.948031497111987]\n",
      "activation function used softmax\n",
      "Running MAP:\t380162.875...194853.890625...186672.375...183160.296875...180450.40625...177724.140625...175186.421875...172589.984375...169973.078125...167453.5625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7640728950500488\n",
      "activation function used softmax\n",
      "BMA prediction [[10.072417  8.260964  9.040054  8.726426  8.229143]]\n",
      "LR prediction [1] 9.806756 7.508149 9.707234 9.454299 8.660698\n",
      "\n",
      "GAM prediction [1] 9.637904 8.373528 9.611384 9.387468 8.776978\n",
      "\n",
      "pred_std tf.Tensor(0.64266676, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([10.072417  8.260964  9.040054  8.726426  8.229143], shape=(5,), dtype=float32)\n",
      "[[ 8.81279    7.0013375  7.7804275  7.4667993  6.9695163]\n",
      " [11.332045   9.520592  10.299681   9.986053   9.48877  ]]\n",
      "[[10.041177 ]\n",
      " [ 7.8931036]\n",
      " [ 9.7575   ]\n",
      " [ 7.8369746]\n",
      " [ 7.4827585]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.5589591860771179\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[9.966008]\n",
      " [8.244575]\n",
      " [9.032518]\n",
      " [8.72381 ]\n",
      " [8.235121]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8173488974571228\n",
      "[[9.912938]\n",
      " [8.21414 ]\n",
      " [8.946213]\n",
      " [8.610274]\n",
      " [8.221743]]\n",
      "Running MAP:\t203540.921875...85792.8828125...45664.01953125...27084.578125...17263.533203125...11771.86328125...8674.8193359375...6983.353515625...6130.41259765625...5760.99462890625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7580227255821228\n",
      "[[9.811024 ]\n",
      " [8.098106 ]\n",
      " [8.840898 ]\n",
      " [8.506586 ]\n",
      " [8.0990305]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194, 0.7866578, 0.9330785, 0.6336097] [0.45845175, 0.48395, 1.5277816, 0.83301526, 0.85884315, 0.7707243, 0.88773113, 0.6199655] [0.40076512, 0.46183637, 1.5521771, 0.8562931, 0.9825734, 0.7194503, 0.81581163, 0.59385633]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704, 1.0506878, 1.1156065, 1.6789109, 0.9315516] [1.2914319, 0.85249555, 0.804008, 0.8054207, 1.1123323, 1.0210264, 1.5407387, 0.8725414] [1.0085629, 0.80004853, 0.83011866, 0.85218525, 1.4519392, 0.89832944, 1.3005803, 0.810892]\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 37 38 40 41 42 43 44 45 46 47 48 49 50] [ 9 19 21 36 39]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449, 0.9174909342215606, 0.8068320585424489]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746, 1.0533299501118047, 0.6232392194797506, 1.1710676167815903, 0.948031497111987, 0.6377134671657102]\n",
      "activation function used softmax\n",
      "Running MAP:\t370836.21875...199057.859375...189818.09375...185305.0...181758.46875...178591.484375...175971.46875...173480.734375...170939.6875...168659.125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8344733715057373\n",
      "activation function used softmax\n",
      "BMA prediction [[8.550024 9.038415 8.718936 8.106538 8.296597]]\n",
      "LR prediction [1] 7.816301 9.098742 9.098351 7.983029 7.382142\n",
      "\n",
      "GAM prediction [1] 8.212284 8.921155 8.135321 8.099312 7.519219\n",
      "\n",
      "pred_std tf.Tensor(0.7266173, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([8.550024 9.038415 8.718936 8.106538 8.296597], shape=(5,), dtype=float32)\n",
      "[[ 7.125854   7.614245   7.294766   6.682368   6.8724265]\n",
      " [ 9.974194  10.4625845 10.1431055  9.530707   9.720766 ]]\n",
      "[[9.035897 ]\n",
      " [9.955856 ]\n",
      " [8.191735 ]\n",
      " [7.5737705]\n",
      " [7.5904346]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.7928187847137451\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[8.549367 ]\n",
      " [9.060149 ]\n",
      " [8.797884 ]\n",
      " [8.113021 ]\n",
      " [8.4650545]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.8143106698989868\n",
      "[[8.494418]\n",
      " [9.028714]\n",
      " [8.708753]\n",
      " [7.995656]\n",
      " [8.450928]]\n",
      "Running MAP:\t263218.875...109875.6875...58375.92578125...34438.19140625...21689.3125...14458.6337890625...10283.52734375...7916.19921875...6647.39013671875...6037.6826171875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6617243885993958\n",
      "[[8.326684 ]\n",
      " [8.857326 ]\n",
      " [8.534641 ]\n",
      " [7.8236823]\n",
      " [8.269    ]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194, 0.7866578, 0.9330785, 0.6336097, 0.70173645] [0.45845175, 0.48395, 1.5277816, 0.83301526, 0.85884315, 0.7707243, 0.88773113, 0.6199655, 0.68389106] [0.40076512, 0.46183637, 1.5521771, 0.8562931, 0.9825734, 0.7194503, 0.81581163, 0.59385633, 0.6856012]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704, 1.0506878, 1.1156065, 1.6789109, 0.9315516, 0.82733613] [1.2914319, 0.85249555, 0.804008, 0.8054207, 1.1123323, 1.0210264, 1.5407387, 0.8725414, 0.8075565] [1.0085629, 0.80004853, 0.83011866, 0.85218525, 1.4519392, 0.89832944, 1.3005803, 0.810892, 0.8200763]\n",
      "[ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 48 50] [ 0  3 44 47 49]\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n",
      "[0.4849554265795824, 0.5286288478541905, 1.2608314607286146, 0.8828230281854038, 0.791180220266405, 0.6922920816976796, 0.7630985596025449, 0.9174909342215606, 0.8068320585424489, 1.4073350006838665]\n",
      "[0.40761262064273013, 0.6200543961089939, 1.0748247171656942, 1.0887723573162746, 1.0533299501118047, 0.6232392194797506, 1.1710676167815903, 0.948031497111987, 0.6377134671657102, 1.2830498284441343]\n",
      "activation function used softmax\n",
      "Running MAP:\t262122.46875...125397.1875...119465.8125...116830.1015625...113339.21875...110318.390625...107639.6875...105324.6015625...103518.9296875...102184.046875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7173975110054016\n",
      "activation function used softmax\n",
      "BMA prediction [[9.199728 8.800214 5.113625 5.98936  9.105335]]\n",
      "LR prediction [1] 9.139448 9.068365 4.094175 4.718711 8.767501\n",
      "\n",
      "GAM prediction [1] 9.294020 9.288111 3.922369 5.270176 9.625110\n",
      "\n",
      "pred_std tf.Tensor(1.993662, shape=(), dtype=float32)\n",
      "pred_mean tf.Tensor([9.199728 8.800214 5.113625 5.98936  9.105335], shape=(5,), dtype=float32)\n",
      "[[ 5.2921505  4.8926363  1.2060475  2.0817823  5.1977577]\n",
      " [13.107306  12.707791   9.021202   9.896937  13.012913 ]]\n",
      "[[ 8.835652 ]\n",
      " [ 9.485    ]\n",
      " [ 1.58     ]\n",
      " [ 3.8864079]\n",
      " [10.387156 ]]\n",
      "BMA-mean:\n",
      "activation function used softmax\n",
      "Running MCMC:\tAcceptance Ratio: 0.6113154292106628\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "activation function used softmax\n",
      "[[9.1999235]\n",
      " [8.920615 ]\n",
      " [5.113623 ]\n",
      " [5.9893584]\n",
      " [9.105335 ]]\n",
      "Running MCMC:\tAcceptance Ratio: 0.828659176826477\n",
      "[[9.15855  ]\n",
      " [8.896608 ]\n",
      " [5.0456095]\n",
      " [5.899762 ]\n",
      " [9.094683 ]]\n",
      "Running MAP:\t135878.03125...55846.4609375...29420.38671875...17377.51171875...11124.0078125...7729.52001953125...5909.7958984375...4998.34130859375...4602.39208984375...4470.576171875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7526733875274658\n",
      "[[9.087835 ]\n",
      " [8.822664 ]\n",
      " [4.9577045]\n",
      " [5.8168426]\n",
      " [9.002041 ]]\n",
      "rmse:\n",
      "[0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194, 0.7866578, 0.9330785, 0.6336097, 0.70173645, 1.9495219] [0.45845175, 0.48395, 1.5277816, 0.83301526, 0.85884315, 0.7707243, 0.88773113, 0.6199655, 0.68389106, 1.907092] [0.40076512, 0.46183637, 1.5521771, 0.8562931, 0.9825734, 0.7194503, 0.81581163, 0.59385633, 0.6856012, 1.8738352]\n",
      "nll:\n",
      "[1.377998, 0.92900085, 0.8009757, 0.8000704, 1.0506878, 1.1156065, 1.6789109, 0.9315516, 0.82733613, 0.9775944] [1.2914319, 0.85249555, 0.804008, 0.8054207, 1.1123323, 1.0210264, 1.5407387, 0.8725414, 0.8075565, 0.9627961] [1.0085629, 0.80004853, 0.83011866, 0.85218525, 1.4519392, 0.89832944, 1.3005803, 0.810892, 0.8200763, 0.9308597]\n",
      "RMSE LR:  0.8535467618362297 0.799006139404427 0.2755349737889978\n",
      "RMSE GAM:  0.8907695670328671 1.0006807236118958 0.27885017937499534\n",
      "RMSE BMA-mean:  0.9128458 0.7917347 0.44186258\n",
      "RMSE BMA:  0.90314466 0.80186975 0.43868822\n",
      "RMSE BAE:  0.89422 0.76763093 0.44751358\n",
      "NLL LR:  0.95211065 0.91061574 0.12822385\n",
      "NLL GAM:  1.1780255 1.0415206 0.32689503\n",
      "NLL BMA-mean:  1.0489732 0.954573 0.26746517\n",
      "NLL BMA:  1.0070347 0.91766876 0.23293616\n",
      "NLL BAE:  0.97035915 0.8752574 0.21443559\n",
      "Coverage LR:  0.9411764705882353\n",
      "Coverage GAM:  0.9019607843137255\n",
      "Coverage BMA-mean:  0.9215686274509803\n",
      "Coverage BMA:  0.9215686274509803\n",
      "Coverage BAE:  0.9411764705882353\n",
      "coverage bma 2\n",
      "0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2 import robjects as ro\n",
    "import rpy2\n",
    "kf = KFold(n_splits=10, random_state=bma_seed, shuffle=True)\n",
    "\n",
    "rmse_lr = []\n",
    "rmse_gam = []\n",
    "rmse_bma = []\n",
    "rmse_bae = []\n",
    "rmse_bma2 = []\n",
    "rmse_bma_mean = []\n",
    "\n",
    "\n",
    "nll_lr, nll_gam, nll_bma_mean, nll_bma, nll_bae = [], [], [], [], []\n",
    "nll_bma2 = []\n",
    "# initialize a dataframe to store lon, lat and raw error\n",
    "error_df = pd.DataFrame(columns=['lon', 'lat', 'raw_error'])\n",
    "\n",
    "coverage_lr, coverage_gam, coverage_bma_mean, coverage_bma, coverage_bae = 0, 0, 0, 0, 0\n",
    "coverage_bma2 = 0\n",
    "#from rpy2.robjects import pandas2ri\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "#ms = importr('MSGARCH')\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  # convert \"lon\" and \"lat\" in training_eastMA_noMI into scaled X_train1 values\n",
    "  training_eastMA_noMI[\"lon\"] = (\n",
    "      training_eastMA_noMI[\"lon\"] - X_centr[0]) / X_scale[0]\n",
    "  training_eastMA_noMI[\"lat\"] = (\n",
    "      training_eastMA_noMI[\"lat\"] - X_centr[1]) / X_scale[1]\n",
    "  r_from_pd_df = ro.conversion.py2rpy(training_eastMA_noMI)\n",
    "\n",
    "\n",
    "mgcv = importr('mgcv')\n",
    "stats = importr('stats')\n",
    "ciTools = importr('ciTools')\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=bma_seed, shuffle=True)\n",
    "rmse_bma_mean, rmse_bma2, rmse_bae = [], [], []\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "    #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_tr, X_te = X_train1[train_index], X_train1[test_index]\n",
    "    Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    base_preds_tr, base_preds_te = base_preds_train.numpy(\n",
    "    )[train_index], base_preds_train.numpy()[test_index]\n",
    "    print(train_index, test_index)\n",
    "    print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape,\n",
    "          base_preds_tr.shape, base_preds_te.shape)\n",
    "\n",
    "    r_dat_py = training_eastMA_noMI\n",
    "\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        r_tr = ro.conversion.py2rpy(r_dat_py.iloc[train_index])\n",
    "        r_te = ro.conversion.py2rpy(r_dat_py.iloc[test_index])\n",
    "\n",
    "    # Ref: lr\n",
    "    lr_model = stats.lm(ro.Formula(\n",
    "        'aqs~pred_av+pred_gs+pred_caces'), data=r_tr)\n",
    "    l = ciTools.add_pi(r_te, lr_model)\n",
    "    lr_pred = l[7]\n",
    "    lr_ci_l, lr_ci_u = l[8], l[9]\n",
    "    coverage_lr += np.sum([(Y_te[i] > lr_ci_l[i]) &\n",
    "                          (Y_te[i] < lr_ci_u[i]) for i in range(len(Y_te))])\n",
    "    rmse_lr.append(rmse(Y_te, np.asanyarray(lr_pred).reshape(-1, 1)))\n",
    "    nll_lr.append(nll(Y_te, np.asanyarray(lr_pred).reshape(-1, 1)))\n",
    "    print(rmse_lr)\n",
    "\n",
    "    # Ref: GAM\n",
    "    #df = training_eastMA_noMI.iloc[train_index]\n",
    "    gam_model = mgcv.gam(ro.Formula(\n",
    "        'aqs ~ s(lon, lat, by=pred_av, k=4) + s(lon, lat,by=pred_gs, k=4) +s(lon, lat, by=pred_caces, k=4)'), data=r_tr)\n",
    "    a = ciTools.add_pi(r_te, gam_model)\n",
    "    gam_pred = a[7]\n",
    "    gam_ci_l, gam_ci_u = a[8], a[9]\n",
    "    coverage_gam += np.sum([(Y_te[i] > gam_ci_l[i]) &\n",
    "                           (Y_te[i] < gam_ci_u[i]) for i in range(len(Y_te))])\n",
    "    rmse_gam.append(rmse(Y_te, np.asanyarray(gam_pred).reshape(-1, 1)))\n",
    "    nll_gam.append(nll(Y_te, np.asanyarray(gam_pred).reshape(-1, 1)))\n",
    "    print(rmse_gam)\n",
    "\n",
    "    bma_prior, bma_gp_config = bma_dist(X_tr,\n",
    "                                        base_preds_tr,\n",
    "                                        **bma_model_config)\n",
    "\n",
    "    bma_model_config.update(bma_gp_config)\n",
    "\n",
    "    bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior,\n",
    "                                               model_config=bma_model_config,\n",
    "                                               Y=Y_tr,\n",
    "                                               map_config=map_config,\n",
    "                                               mcmc_config=mcmc_config)\n",
    "\n",
    "        #fixed_input_te = tf.ones((X_te.shape[0], 2), dtype=tf.float32)\n",
    "    bma_joint_samples = make_bma_samples(X_te, None, base_preds_te,\n",
    "                                         bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                         bma_model_config=bma_model_config,\n",
    "                                         n_samples=bma_n_samples_eval,\n",
    "                                         seed=bne_seed,\n",
    "                                         y_samples_only=False)\n",
    "    y_pred = bma_joint_samples['y']\n",
    "    y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "    \n",
    "    print(\"BMA prediction\", y_pred.numpy().T)\n",
    "    print(\"LR prediction\", lr_pred)\n",
    "    print(\"GAM prediction\", gam_pred)\n",
    "    pred_std = calc_prediction_std(y_pred, Y_te)\n",
    "    print(\"pred_std\", pred_std)\n",
    "    pred_mean = tf.reduce_mean(y_pred, axis=1)\n",
    "    print(\"pred_mean\",pred_mean)\n",
    "    bma_pi = np.array([(pred_mean - 1.96*pred_std).numpy(),\n",
    "                      (pred_mean + 1.96*pred_std).numpy()])\n",
    "    print(bma_pi)\n",
    "    rmse_bma.append(rmse(Y_te, y_pred))\n",
    "    nll_bma2.append(nll(Y_te, y_pred))\n",
    "    coverage_bma2 += np.sum([(Y_te[i] > bma_pi[0][i]) & (Y_te[i] < bma_pi[1][i]) for i in range(len(Y_te))])\n",
    "                            \n",
    "    # Create data dictionary.\n",
    "    data_dicts = dict(X_train=X_tr,\n",
    "                      X_test=X_te,\n",
    "                      Y_train=Y_tr,\n",
    "                      base_preds_train=base_preds_tr,\n",
    "                      base_preds_test=base_preds_te)\n",
    "\n",
    "    print(Y_te)\n",
    "    # BMA-mean.\n",
    "    print('BMA-mean:', flush=True)\n",
    "    data_dict, bma_mean_joint_samples = get_bma_result(\n",
    "        data_dicts, bma_config=bma_config)\n",
    "    y_pred_bma_mean = np.mean(np.nan_to_num(\n",
    "        bma_mean_joint_samples['y']), axis=0)\n",
    "    pred_std = calc_prediction_std(y_pred_bma_mean, Y_te)\n",
    "    bma_mean_pi = np.array([(y_pred_bma_mean - 1.96*pred_std).numpy(), (y_pred_bma_mean + 1.96*pred_std).numpy()])\n",
    "    print(y_pred_bma_mean)\n",
    "\n",
    "    # BMA.\n",
    "    bma_var_config = bne_config.copy()\n",
    "    bma_var_config['mcmc_initialize_from_map'] = bma_config['mcmc_initialize_from_map']\n",
    "    bma_joint_samples = get_bne_result(data_dict, moment_mode='none',\n",
    "                                       bne_config=bma_var_config)\n",
    "    y_pred_bma = np.mean(np.nan_to_num(bma_joint_samples['y']), axis=0)\n",
    "    print(y_pred_bma)\n",
    "    pred_std = calc_prediction_std(y_pred_bma, Y_te)\n",
    "    bma_pi2 = np.array([(y_pred_bma - 1.96*pred_std).numpy(), (y_pred_bma + 1.96*pred_std).numpy()])\n",
    "\n",
    "    # BAE.\n",
    "    bae_joint_samples = get_bne_result(data_dict, moment_mode='mean',\n",
    "                                       bne_config=bne_config)\n",
    "    y_pred_bae = np.mean(np.nan_to_num(bae_joint_samples['y']), axis=0)\n",
    "    print(y_pred_bae)\n",
    "    pred_std = calc_prediction_std(y_pred_bae, Y_te)\n",
    "    bae_pi = np.array([(y_pred_bae - 1.96*pred_std).numpy(), (y_pred_bae + 1.96*pred_std).numpy()])\n",
    "    \n",
    "    # save the rmse & nll for each fold\n",
    "    rmse_bma_mean.append(rmse(Y_te, y_pred_bma_mean))\n",
    "    nll_bma_mean.append(nll(Y_te, y_pred_bma_mean))\n",
    "    rmse_bma2.append(rmse(Y_te, y_pred_bma))\n",
    "    nll_bma.append(nll(Y_te, y_pred_bma))\n",
    "    rmse_bae.append(rmse(Y_te, y_pred_bae))\n",
    "    nll_bae.append(nll(Y_te, y_pred_bae))\n",
    "   \n",
    "    # save the coverage for each fold\n",
    "    coverage_bma_mean += np.sum([(Y_te[i] > bma_mean_pi[0][i]) & (Y_te[i] < bma_mean_pi[1][i]) for i in range(len(Y_te))])\n",
    "    coverage_bma += np.sum([(Y_te[i] > bma_pi2[0][i]) & (Y_te[i] < bma_pi2[1][i]) for i in range(len(Y_te))])\n",
    "    coverage_bae += np.sum([(Y_te[i] > bae_pi[0][i]) & (Y_te[i] < bae_pi[1][i]) for i in range(len(Y_te))])\n",
    "    \n",
    "    raw_error = pd.DataFrame(columns=['lon', 'lat', 'raw_error'])\n",
    "    raw_error[\"lon\"] = X_te[:,0]\n",
    "    raw_error[\"lat\"] = X_te[:,1]\n",
    "    raw_error[\"raw_error\"] = (y_pred_bae - Y_te).reshape(-1)\n",
    "    error_df = error_df.append(raw_error)\n",
    "    print(\"rmse:\", flush=True)\n",
    "    print(rmse_bma_mean, rmse_bma2, rmse_bae)\n",
    "    print(\"nll:\", flush=True)\n",
    "    print(nll_bma_mean, nll_bma, nll_bae)\n",
    "\n",
    "    # raw_error = pd.DataFrame(columns=['lon', 'lat', 'raw_error'])\n",
    "    # raw_error[\"lon\"] = X_te[:, 0]\n",
    "    # raw_error[\"lat\"] = X_te[:, 1]\n",
    "    # raw_error[\"raw_error\"] = (y_pred - Y_te).numpy().reshape(-1)\n",
    "    # error_df = error_df.append(raw_error)\n",
    "\n",
    "    # pred_std = calc_prediction_std(y_pred, Y_te)\n",
    "    # pred_mean = tf.reduce_mean(y_pred, axis=1)\n",
    "    # bma_pi = np.array([(pred_mean - 1.96*pred_std).numpy(),\n",
    "    #                   (pred_mean + 1.96*pred_std).numpy()])\n",
    "    # coverage_bma += np.sum([(Y_te[i] > bma_pi[0][i]) &\n",
    "    #                        (Y_te[i] < bma_pi[1][i]) for i in range(len(Y_te))])\n",
    "    # rmse_bma.append(rmse(Y_te, y_pred))\n",
    "    # nll_bma.append(nll(Y_te, y_pred))\n",
    "    # print(rmse_bma)\n",
    "    # Investigate what examples (e.g., in terms of spatial coordinate) tend to receive high error.\n",
    "\n",
    "# # save rmse average among folds\n",
    "# average_metrics = np.mean(\n",
    "#     [rmse_bma_mean, rmse_bma2, rmse_bae], axis=1)\n",
    "# print(average_metrics)\n",
    "\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.median(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE GAM: \", np.mean(rmse_gam), np.median(rmse_gam), np.std(rmse_gam))\n",
    "print(\"RMSE BMA-mean: \", np.mean(rmse_bma_mean), np.median(rmse_bma_mean), np.std(rmse_bma_mean))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma2), np.median(rmse_bma2), np.std(rmse_bma2))\n",
    "print(\"RMSE BAE: \", np.mean(rmse_bae), np.median(rmse_bae), np.std(rmse_bae))\n",
    "\n",
    "print(\"NLL LR: \", np.mean(nll_lr), np.median(nll_lr), np.std(nll_lr))\n",
    "print(\"NLL GAM: \", np.mean(nll_gam), np.median(nll_gam), np.std(nll_gam))\n",
    "print(\"NLL BMA-mean: \", np.mean(nll_bma_mean), np.median(nll_bma_mean), np.std(nll_bma_mean))\n",
    "print(\"NLL BMA: \", np.mean(nll_bma), np.median(nll_bma), np.std(nll_bma))\n",
    "print(\"NLL BAE: \", np.mean(nll_bae), np.median(nll_bae), np.std(nll_bae))\n",
    "\n",
    "print(\"Coverage LR: \", coverage_lr/len(Y_train))\n",
    "print(\"Coverage GAM: \", coverage_gam/len(Y_train))\n",
    "print(\"Coverage BMA-mean: \", coverage_bma_mean/len(Y_train))\n",
    "print(\"Coverage BMA: \", coverage_bma/len(Y_train))\n",
    "print(\"Coverage BAE: \", coverage_bae/len(Y_train))\n",
    "\n",
    "print(\"coverage bma 2\", flush=True)\n",
    "print(coverage_bma2/len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE LR:  0.8535467618362297 0.799006139404427 0.2755349737889978\n",
      "RMSE GAM:  0.8906541796017822 1.000680723615343 0.2787684492528292\n",
      "RMSE BMA-mean:  0.9128458 0.7917347 0.44186258\n",
      "RMSE BMA:  0.9128458 0.7917347 0.44186258\n",
      "RMSE BAE:  0.8941223 0.7671427 0.44753078\n",
      "NLL LR:  0.95211065 0.91061574 0.12822385\n",
      "NLL GAM:  1.1780632 1.0415206 0.3268624\n",
      "NLL BMA-mean:  1.0489732 0.954573 0.26746517\n",
      "NLL BMA:  1.0489732 0.954573 0.26746517\n",
      "NLL BAE:  0.9700297 0.87525725 0.21393003\n",
      "Coverage LR:  0.9411764705882353\n",
      "Coverage GAM:  0.9019607843137255\n",
      "Coverage BMA-mean:  0.9215686274509803\n",
      "Coverage BMA:  0.9215686274509803\n",
      "Coverage BAE:  0.9411764705882353\n",
      "coverage bma 2\n",
      "0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.median(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE GAM: \", np.mean(rmse_gam), np.median(rmse_gam), np.std(rmse_gam))\n",
    "print(\"RMSE BMA-mean: \", np.mean(rmse_bma_mean), np.median(rmse_bma_mean), np.std(rmse_bma_mean))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma2), np.median(rmse_bma2), np.std(rmse_bma2))\n",
    "print(\"RMSE BAE: \", np.mean(rmse_bae), np.median(rmse_bae), np.std(rmse_bae))\n",
    "\n",
    "print(\"NLL LR: \", np.mean(nll_lr), np.median(nll_lr), np.std(nll_lr))\n",
    "print(\"NLL GAM: \", np.mean(nll_gam), np.median(nll_gam), np.std(nll_gam))\n",
    "print(\"NLL BMA-mean: \", np.mean(nll_bma_mean), np.median(nll_bma_mean), np.std(nll_bma_mean))\n",
    "print(\"NLL BMA: \", np.mean(nll_bma), np.median(nll_bma), np.std(nll_bma))\n",
    "print(\"NLL BAE: \", np.mean(nll_bae), np.median(nll_bae), np.std(nll_bae))\n",
    "\n",
    "print(\"Coverage LR: \", coverage_lr/len(Y_train))\n",
    "print(\"Coverage GAM: \", coverage_gam/len(Y_train))\n",
    "print(\"Coverage BMA-mean: \", coverage_bma_mean/len(Y_train))\n",
    "print(\"Coverage BMA: \", coverage_bma/len(Y_train))\n",
    "print(\"Coverage BAE: \", coverage_bae/len(Y_train))\n",
    "\n",
    "print(\"coverage bma 2\", flush=True)\n",
    "print(coverage_bma2/len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE LR:  0.8535467618362297 0.799006139404427 0.2755349737889978\n",
      "RMSE GAM:  0.8906541796017822 1.000680723615343 0.2787684492528292\n",
      "RMSE BMA:  0.9128458 0.7917347 0.44186258\n",
      "RMSE BMA-Mean:  0.9128458 0.7917347 0.44186258\n",
      "RMSE BMA: 0.90089035 0.69356775 0.4916007\n",
      "RMSE BAE:  0.8941223 0.7671427 0.44753078\n",
      "RMSE BMA-Mean:  [0.5096889, 0.48968843, 1.5228623, 0.7968115, 0.80480194, 0.7866578, 0.9330785, 0.6336097, 0.70173645, 1.9495219]\n",
      "RMSE BMA: [0.5184996, 0.4869609, 1.7351234, 0.8082389, 0.60736626, 0.9227745, 0.7517346, 0.63540095, 0.58558244, 1.957222]\n",
      "RMSE BAE:  [0.40076494, 0.4618366, 1.5521771, 0.85629296, 0.9825734, 0.7194507, 0.8148347, 0.5938562, 0.6856015, 1.8738352]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.median(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE GAM: \", np.mean(rmse_gam), np.median(rmse_gam), np.std(rmse_gam))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma2), np.median(rmse_bma2), np.std(rmse_bma2))\n",
    "print(\"RMSE BMA-Mean: \", np.mean(rmse_bma_mean), np.median(rmse_bma_mean), np.std(rmse_bma_mean))\n",
    "print(\"RMSE BMA:\", np.mean(rmse_bma), np.median(rmse_bma), np.std(rmse_bma))\n",
    "print(\"RMSE BAE: \", np.mean(rmse_bae), np.median(rmse_bae), np.std(rmse_bae))\n",
    "\n",
    "print(\"RMSE BMA-Mean: \", rmse_bma_mean)\n",
    "print(\"RMSE BMA:\", rmse_bma)\n",
    "print(\"RMSE BAE: \", rmse_bae)\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcc6cf470fa43d25f7728c2f3c746fc9b5580c34ff527761ed8536047e15184c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
