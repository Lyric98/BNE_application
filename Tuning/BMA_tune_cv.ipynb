{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 13:26:32.195575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 13:26:56.877768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions import *\n",
    "from ensemble import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAYcMR698j6J"
   },
   "source": [
    "# Experiment II: 2D Spatial Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AMIJk1OdKIj7"
   },
   "outputs": [],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .07 # @param\n",
    "bma_gp_l2_regularizer = 0.15 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9iyxQiCJKIn7"
   },
   "outputs": [],
   "source": [
    "# BNE parameters.\n",
    "bne_gp_lengthscale = .1 # 5. # @param\n",
    "bne_gp_l2_regularizer = .05 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training/prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(55, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(84421, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred longitude max and min -69.93 -73.5\n",
      "pred latitude max and min 44.3 40.6\n",
      "train longitude max and min -70.023598 -73.443056\n",
      "train latitude max and min 44.107524 40.74529\n"
     ]
    }
   ],
   "source": [
    "training_eastMA = pd.read_csv('../data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('../data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('../data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "display(training_eastMA.shape, training_eastMA_folds.shape, base_model_predictions_eastMA.shape)\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())\n",
    "\n",
    "\n",
    "training51= pd.read_csv('../data/training_dataset/training51.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 center and scale:  [-72.185104  42.680347] [3.5699997 3.7000008]\n"
     ]
    }
   ],
   "source": [
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([51, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([84421, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "#base_preds_test\n",
    "display(base_preds_train.shape, base_preds_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        2        10        11        22        28        29 \n",
      "10.211692  9.819233  5.673589  9.639125  5.343900  9.012283 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        4        26        32        33        45 \n",
      " 9.746925  8.858188  9.322724 10.035579  7.173532 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       7       27       34       35       41 \n",
      "5.753455 8.372504 9.240131 8.482528 5.604121 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14       18       42       46       48 \n",
      "9.626291 8.633853 5.783775 7.117513 6.564034 \n",
      "\n",
      "      15       16       30       31       43 \n",
      "8.608835 8.608332 8.629879 8.368166 7.697025 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8       13       20       25       50 \n",
      "9.300969 9.357386 5.450329 7.711960 7.988648 \n",
      "\n",
      "        1         5        17        37        40 \n",
      "10.588809  9.398915  6.534695  8.884988  4.260287 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6       12       23       24       38 \n",
      "9.605954 8.443477 9.640203 9.419740 8.772681 \n",
      "\n",
      "       9       19       21       36       39 \n",
      "8.212285 8.921156 8.135322 8.099314 7.519223 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0        3       44       47       49 \n",
      "9.294020 9.288111 3.922368 5.270174 9.625108 \n",
      "\n",
      "[1.6682197, 0.8446648, 2.0171714, 0.9632994, 1.7046735, 1.3922702, 2.009299, 0.8785388, 0.85990846, 3.6984842] [0.4076122911410147, 0.620054865920744, 1.074823763530061, 1.0825851802176598, 1.053331252914463, 0.6232383511079379, 1.171068512762113, 0.9669676644344501, 0.6377131437768805, 1.2830493171899717]\n",
      "RMSE LR:  1.603653 0.82752544\n",
      "RMSE GAM:  0.8920444342995296 0.2788681022382428\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "#ms = importr('MSGARCH')\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_from_pd_df = ro.conversion.py2rpy(training_eastMA_noMI)\n",
    "\n",
    "r_from_pd_df\n",
    "\n",
    "mgcv  = importr('mgcv')\n",
    "stats = importr('stats')\n",
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "      Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "      base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "      \n",
    "      # Ref: linear regression\n",
    "      ref_model.fit(X_tr, Y_tr)\n",
    "      Y_pred = ref_model.predict(X_te)\n",
    "      rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "\n",
    "      r_dat_py = training_eastMA_noMI\n",
    "      r_dat_py[['lon', 'lat']] = X_train1\n",
    "      \n",
    "      with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            r_tr = ro.conversion.py2rpy(r_dat_py.iloc[train_index])\n",
    "            r_te = ro.conversion.py2rpy(r_dat_py.iloc[test_index])\n",
    "\n",
    "      # Ref: GAM\n",
    "      #df = training_eastMA_noMI.iloc[train_index]\n",
    "      gam_model = mgcv.gam(ro.Formula('aqs ~ s(lon, lat, by=pred_av, k=4) + s(lon, lat,by=pred_gs, k=4) +s(lon, lat, by=pred_caces, k=4)'), data=r_tr)\n",
    "      a=stats.predict(gam_model, newdata =r_te)\n",
    "      print(a)\n",
    "      rmse_gam.append(rmse(Y_te, np.asanyarray(a).reshape(-1,1)))\n",
    "      #print(rmse_gam)\n",
    "\n",
    "print(rmse_lr, rmse_gam)\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE GAM: \", np.mean(rmse_gam), np.std(rmse_gam))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Family: gaussian \n",
      "Link function: identity \n",
      "\n",
      "Formula:\n",
      "aqs ~ s(lon, lat, by = pred_av, k = 4) + s(lon, lat, by = pred_gs, \n",
      "    k = 4) + s(lon, lat, by = pred_caces, k = 4)\n",
      "\n",
      "Parametric coefficients:\n",
      "            Estimate Std. Error t value Pr(>|t|)\n",
      "(Intercept)   0.1594     1.3619   0.117    0.908\n",
      "\n",
      "Approximate significance of smooth terms:\n",
      "                      edf Ref.df     F p-value   \n",
      "s(lon,lat):pred_av      3      3 3.472 0.02589 * \n",
      "s(lon,lat):pred_gs      3      3 1.115 0.35593   \n",
      "s(lon,lat):pred_caces   3      3 5.712 0.00264 **\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "R-sq.(adj) =  0.748   Deviance explained = 79.9%\n",
      "GCV = 0.72953  Scale est. = 0.57094   n = 46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(base.summary(gam_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "      Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "      base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "      \n",
    "      # Ref: linear regression\n",
    "      ref_model.fit(X_tr, Y_tr)\n",
    "      Y_pred = ref_model.predict(X_te)\n",
    "      rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "\n",
    "      # Ref: GAM\n",
    "      #df = training_eastMA_noMI.iloc[train_index]\n",
    "      \n",
    "      gam_model = GAMEnsemble()\n",
    "      gam_model.train(X_tr, Y_tr, base_preds_tr)\n",
    "      y_gam_pred, y_gam_pred_se = (\n",
    "            gam_model.predict(X_te, base_preds_te))\n",
    "      #rmse_gam.append(rmse(Y_te, gam_pred))\n",
    "      #print(rmse_gam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16446114],\n",
       "       [ 0.4400692 ],\n",
       "       [-0.15744448],\n",
       "       [-0.0414896 ],\n",
       "       [-3.911059  ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_te -Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAMEnsemble(EnsembleModel):\n",
    "    \"\"\"Implements GAM ensemble in [1].\"\"\"\n",
    "\n",
    "    def __init__(self, nonlinear_ensemble=False, residual_process=True):\n",
    "        \"\"\"\n",
    "        Initializer.\n",
    "\n",
    "        Args:\n",
    "            nonlinear_ensemble: (bool) Whether use nonlinear term to transform base model.\n",
    "            residual_process: (bool) Whether model residual process.\n",
    "        \"\"\"\n",
    "        model_name = (\n",
    "            \"Generalized Additive Ensemble\" if residual_process\n",
    "            else \"{} Stacking\".format(\"Nonlinear\" if nonlinear_ensemble else \"Linear\"))\n",
    "\n",
    "        super().__init__(model_name)\n",
    "        self.gam_model = None\n",
    "        self.nonlinear_ensemble = nonlinear_ensemble\n",
    "        self.model_residual = residual_process\n",
    "\n",
    "    def train(self, X, y, base_pred):\n",
    "        \"\"\"Trains ensemble model based on data and base predictions.\n",
    "\n",
    "        Adds value to class attribute \"model_weight\"\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray) Training features, shape (N, D)\n",
    "            y: (np.ndarray)  Training labels, shape (N, 1)\n",
    "            base_pred: (dict of np.ndarray) Dictionary of base model predictions\n",
    "                With keys (str) being model name, and values (np.ndarray) being\n",
    "                predictions corresponds to X and y.\n",
    "        \"\"\"\n",
    "        # build feature and  gam terms\n",
    "        ens_feature, feature_terms = self._build_ensemble_feature(X, base_pred)\n",
    "\n",
    "        # define model\n",
    "        self.gam_model = LinearGAM(feature_terms)\n",
    "\n",
    "        # additional fine-tuning\n",
    "        lam_grid = self._build_lambda_grid(n_grid=100)\n",
    "        self.gam_model.gridsearch(X=ens_feature, y=y, lam=lam_grid,\n",
    "                                  progress=False)\n",
    "\n",
    "    def predict(self, X, base_pred):\n",
    "        \"\"\"Predicts label based on feature and base model.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray) Training features, shape (N, D)\n",
    "            base_pred: (dict of np.ndarray) Dictionary of base model predictions\n",
    "                With keys (str) being model name, and values (np.ndarray) being\n",
    "                predictions corresponds to X and y.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray) ensemble prediction and variance\n",
    "\n",
    "        Raises:\n",
    "            (ValueError) If self.model_weight is empty.\n",
    "        \"\"\"\n",
    "        if not self.gam_model:\n",
    "            raise ValueError(\"Attribute gam_model empty.\"\n",
    "                             \"Model was not trained properly.\")\n",
    "\n",
    "        # build feature and  gam terms\n",
    "        ens_feature, _ = self._build_ensemble_feature(X, base_pred)\n",
    "\n",
    "        # prediction\n",
    "        prediction = self.gam_model.predict(ens_feature)\n",
    "        prediction_var = ((self.gam_model.prediction_intervals(\n",
    "            ens_feature, width=.95)[:, 1] - prediction) / 2) ** 2\n",
    "\n",
    "        return prediction, prediction_var\n",
    "\n",
    "    def _build_ensemble_feature(self, X, base_pred):\n",
    "        \"\"\"Builds featurre array and corresponding GAM TermList.\n",
    "\n",
    "        Terms corresponding to X will be summation of\n",
    "            dimension-wise splines, plus a tensor-product term across all dimension.\n",
    "\n",
    "        \"\"\"\n",
    "        ensemble_term_func = s if self.nonlinear_ensemble else l\n",
    "\n",
    "        ens_feature = np.asarray(list(base_pred.values())).T\n",
    "        term_list = [ensemble_term_func(dim_index) for dim_index in range(ens_feature.shape[1])]\n",
    "\n",
    "        # optionally, add residual process\n",
    "        if self.model_residual:\n",
    "            # build gam terms\n",
    "            term_list += [s(dim_index) for dim_index in\n",
    "                          range(ens_feature.shape[1],\n",
    "                                ens_feature.shape[1] + X.shape[1])]\n",
    "            if X.shape[1] > 1:\n",
    "                term_list += [te(*list(ens_feature.shape[1] +\n",
    "                                       np.array(range(X.shape[1]))))]\n",
    "\n",
    "            # update features\n",
    "            ens_feature = np.concatenate([ens_feature, X], axis=1)\n",
    "\n",
    "        gam_feature_terms = TermList(*term_list)\n",
    "\n",
    "        return ens_feature, gam_feature_terms\n",
    "\n",
    "    def _build_lambda_grid(self, n_grid=100):\n",
    "        # count actual number of terms in each nonlinear term\n",
    "        # (e.g. te(0, 1) will actually have two terms)\n",
    "        n_terms = np.sum([len(model_term._terms) if model_term.istensor else 1\n",
    "                          for model_term in self.gam_model.terms])\n",
    "        lam = np.random.rand(n_grid, n_terms)\n",
    "        # rescale to between (0, 1)\n",
    "        lam_norm = (lam - np.min(lam)) / (np.max(lam) - np.min(lam))\n",
    "\n",
    "        return np.exp((lam_norm - 0.5) * 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std,\n",
    "                             activation=None))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 10-fold Random Cross Validation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 9.2      , 10.377717 ,  9.456476 ],\n",
       "       [ 9.8      , 11.016994 ,  9.316178 ],\n",
       "       [ 4.6      ,  8.377447 ,  6.027947 ],\n",
       "       [ 8.6      ,  8.057583 ,  7.3990026]], dtype=float32)>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index of max and min  for lon and lat\n",
    "min_index_lon = training_eastMA_noMI[['lon']].idxmin().values.tolist()\n",
    "max_index_lon = training_eastMA_noMI[['lon']].idxmax().values.tolist()\n",
    "min_index_lat = training_eastMA_noMI[['lat']].idxmin().values.tolist()\n",
    "max_index_lat = training_eastMA_noMI[['lat']].idxmax().values.tolist()\n",
    "# concetenate the index\n",
    "edge_list = min_index_lon + max_index_lon + min_index_lat + max_index_lat\n",
    "# exclude edge_list index from X_train1\n",
    "train_wo_edge = X_train1[~np.isin(np.arange(len(X_train1)), edge_list)]\n",
    "# exclude edge_list index from Y_train\n",
    "Y_wo_edge = Y_train[~np.isin(np.arange(len(Y_train)), edge_list)]\n",
    "# edge_list index from X_train1\n",
    "edge_list_X = X_train1[np.isin(np.arange(len(X_train1)), edge_list)]\n",
    "# edge_list index from Y_train\n",
    "edge_list_Y = Y_train[np.isin(np.arange(len(Y_train)), edge_list)]\n",
    "edge_list_base = base_preds_train[np.isin(np.arange(len(base_preds_train)), edge_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8130488]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Conversion 'py2rpy' not defined for objects of type '<class 'pandas.core.frame.DataFrame'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_19701/3186680275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m#df = training_eastMA_noMI.iloc[train_index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       gam_model = mgcv.gam(ro.Formula('aqs ~s(pred_av) + s(pred_gs) + s(pred_caces)'),\n\u001b[0;32m---> 33\u001b[0;31m        data=training_eastMA_noMI.iloc[train_index])\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0;31m#gam_pred = gam_model.predict(X_te)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;31m#rmse_gam.append(rmse(Y_te, gam_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         return (super(SignatureTranslatedFunction, self)\n\u001b[0;32m--> 204\u001b[0;31m                 .__call__(*args, **kwargs))\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2rpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/rpy2/robjects/conversion.py\u001b[0m in \u001b[0;36m_py2rpy\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m\"Conversion 'py2rpy' not defined for objects of type '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Conversion 'py2rpy' not defined for objects of type '<class 'pandas.core.frame.DataFrame'>'"
     ]
    }
   ],
   "source": [
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=10) \n",
    "\n",
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "      Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "      \n",
    "      # Ref: linear regression\n",
    "      ref_model.fit(X_tr, Y_tr)\n",
    "      Y_pred = ref_model.predict(X_te)\n",
    "      rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "      print(rmse_lr)\n",
    "\n",
    "\n",
    "      base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "      print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape, base_preds_tr.shape, base_preds_te.shape)\n",
    "\n",
    "      # build model & run MCMC\n",
    "      bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "                                    base_preds_tr, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "      bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "      bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_tr, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "      bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "      y_pred = bma_joint_samples['y']\n",
    "      y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "\n",
    "      rmse_bma.append(rmse(Y_te, y_pred))\n",
    "      print(rmse_bma)\n",
    "\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma), np.std(rmse_bma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 10-fold Spatial Cross Validation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_id=10\n",
    "# X_te = X_train1[training51.index[training51[\"fold\"] == fold_id]]\n",
    "# X_tr = X_train1[training51.index[training51[\"fold\"] != fold_id]]\n",
    "# Y_te = Y_train[training51.index[training51[\"fold\"] == fold_id]]\n",
    "# Y_tr = Y_train[training51.index[training51[\"fold\"] != fold_id]]\n",
    "\n",
    "# base_preds_tr=base_preds_train.numpy()[training51.index[training51[\"fold\"] != fold_id]]\n",
    "# base_preds_te=base_preds_train.numpy()[training51.index[training51[\"fold\"] == fold_id]]\n",
    "\n",
    "# # build model & run MCMC\n",
    "# bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "#                                     base_preds_tr, \n",
    "#                                     **bma_model_config)\n",
    "\n",
    "# bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "# bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_tr, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "# bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "#                                      bma_weight_samples=bma_gp_w_samples[0],\n",
    "#                                      bma_model_config=bma_model_config,\n",
    "#                                      n_samples=bma_n_samples_eval, \n",
    "#                                      seed=bne_seed,\n",
    "#                                      y_samples_only=False)\n",
    "# y_pred = bma_joint_samples['y']\n",
    "# y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "\n",
    "# print(rmse(Y_te, y_pred))\n",
    "\n",
    "# # Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "# means_tr_mcmc, X_tr_mcmc, Y_tr_mcmc = make_bma_samples(\n",
    "#     X_tr, Y_tr, base_preds_tr, \n",
    "#     bma_weight_samples=bma_gp_w_samples[0],\n",
    "#     bma_model_config=bma_model_config,\n",
    "#     n_samples=bma_n_samples_train,\n",
    "#     seed=bma_seed, \n",
    "#     prepare_mcmc_training=True)\n",
    "\n",
    "# # Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "# # It is used to generate final examples in `make_bne_samples()`.\n",
    "# means_te_mcmc = make_bma_samples(\n",
    "#     X_te, None, base_preds_te, \n",
    "#     bma_weight_samples=bma_gp_w_samples[0],\n",
    "#     bma_model_config=bma_model_config,\n",
    "#     n_samples=bma_n_samples_test,\n",
    "#     seed=bma_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rmse_bma = []\n",
    "# rmse_bne = []\n",
    "\n",
    "# for fold_id in range(1, 11):\n",
    "#     # prepare cross-validation data\n",
    "#     X_te = X_train1[training51.index[training51[\"fold\"] == fold_id]]\n",
    "#     X_tr = X_train1[training51.index[training51[\"fold\"] != fold_id]]\n",
    "#     Y_te = Y_train[training51.index[training51[\"fold\"] == fold_id]]\n",
    "#     Y_tr = Y_train[training51.index[training51[\"fold\"] != fold_id]]\n",
    "\n",
    "#     base_preds_tr=base_preds_train.numpy()[training51.index[training51[\"fold\"] != fold_id]]\n",
    "#     base_preds_te=base_preds_train.numpy()[training51.index[training51[\"fold\"] == fold_id]]\n",
    "\n",
    "#     # build model & run MCMC\n",
    "#     bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "#                                     base_preds_tr, \n",
    "#                                     **bma_model_config)\n",
    "\n",
    "#     bma_model_config.update(bma_gp_config)\n",
    "\n",
    "#     print(\"BMA model config: \", bma_model_config, \"mcmc_config: \", mcmc_config, \"map_config: \", map_config)\n",
    "#     bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_tr, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "#     bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "#                                      bma_weight_samples=bma_gp_w_samples[0],\n",
    "#                                      bma_model_config=bma_model_config,\n",
    "#                                      n_samples=bma_n_samples_eval, \n",
    "#                                      seed=bne_seed,\n",
    "#                                      y_samples_only=False)\n",
    "\n",
    "#     y_pred = bma_joint_samples['y']\n",
    "#     y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "#     rmse_bma.append(rmse(Y_te, y_pred))\n",
    "#     print(rmse_bma)\n",
    "\n",
    "#     # Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "#     means_tr_mcmc, X_tr_mcmc, Y_tr_mcmc = make_bma_samples(\n",
    "#         X_tr, Y_tr, base_preds_tr, \n",
    "#         bma_weight_samples=bma_gp_w_samples[0],\n",
    "#         bma_model_config=bma_model_config,\n",
    "#         n_samples=bma_n_samples_train,\n",
    "#         seed=bma_seed, \n",
    "#         prepare_mcmc_training=True)\n",
    "\n",
    "#     # Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "#     # It is used to generate final examples in `make_bne_samples()`.\n",
    "#     means_te_mcmc = make_bma_samples(\n",
    "#         X_te, None, base_preds_te, \n",
    "#         bma_weight_samples=bma_gp_w_samples[0],\n",
    "#         bma_model_config=bma_model_config,\n",
    "#         n_samples=bma_n_samples_test,\n",
    "#         seed=bma_seed)\n",
    "\n",
    "#     # # # BNE GP Configs.\n",
    "# # # lengthscale = 1. # @param\n",
    "# # # l2_regularizer = 10. # @param\n",
    "\n",
    "# # BNE model configs. \n",
    "# # If estimate_mean=False, only estimates a constant variance on top of the \n",
    "# # original model.\n",
    "#     estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "#     variance_prior_mean=0. # @param\n",
    "# # # MAP and MCMC configs\n",
    "# # map_step_size=0.1 # @param\n",
    "# # map_num_steps=10_000 # @param\n",
    "\n",
    "# # mcmc_step_size=1e-2 # @param\n",
    "# # mcmc_num_steps=10_000 # @param\n",
    "\n",
    "#     bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "#     bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "#     map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "#     mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "#     bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "#                           l2_regularizer=bne_gp_l2_regularizer))\n",
    "#     bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "#                              variance_prior_mean=variance_prior_mean,\n",
    "#                              **bne_gp_config))\n",
    "\n",
    "#     map_config.update(dict(learning_rate=map_step_size,\n",
    "#                        num_steps=map_num_steps))\n",
    "#     mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "#                         num_steps=mcmc_num_steps,\n",
    "#                        burnin=mcmc_burnin,\n",
    "#                        nchain=mcmc_nchain))\n",
    "    \n",
    "#     # build model & run MCMC\n",
    "#     bne_prior, bne_gp_config = bne_model_dist(\n",
    "#             inputs=X_tr_mcmc,\n",
    "#             mean_preds=means_tr_mcmc,\n",
    "#             **bne_model_config)\n",
    "\n",
    "#     bne_model_config.update(bne_gp_config)\n",
    "\n",
    "#     print(\"BNE model config: \", bne_model_config, \"mcmc_config: \", mcmc_config, \"map_config: \", map_config)\n",
    "#     # Estimates GP weight posterior using MCMC.\n",
    "#     bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "#                                             model_config=bne_gp_config,\n",
    "#                                             Y=Y_tr_mcmc,\n",
    "#                                             map_config=map_config,\n",
    "#                                             mcmc_config=mcmc_config,\n",
    "#                                             initialize_from_map=True)\n",
    "#     # Generates the posterior sample for all model parameters. \n",
    "#     bne_joint_samples = make_bne_samples(X_te,\n",
    "#                                         mean_preds=means_te_mcmc,\n",
    "#                                         bne_model_config=bne_model_config,\n",
    "#                                         bne_weight_samples=bne_gp_w_samples[0],\n",
    "#                                         seed=bne_seed)\n",
    "    \n",
    "#     y_pred = bne_joint_samples['y']\n",
    "#     means_pred = np.mean(y_pred, axis=0)\n",
    "#     rmse_bne.append(rmse(Y_te, y_pred))\n",
    "#     print(rmse_bne)\n",
    "\n",
    "    \n",
    "# print(rmse_bma, rmse_bne)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('gp_weights', ()), ('y', ('gp_weights',)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior, bma_gp_config = bma_dist(X_train1, \n",
    "                                    base_preds_train, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "bma_model_config.update(bma_gp_config)\n",
    "\n",
    "# Check if the model graph is specified correctly.\n",
    "bma_prior.resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengthscale': 0.07,\n",
       " 'l2_regularizer': 0.15,\n",
       " 'hidden_units': 1024,\n",
       " 'y_noise_std': 0.01,\n",
       " 'activation': None,\n",
       " 'units': 3,\n",
       " 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bma_model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t409032.25...157770.984375...141512.0625...131225.21875...126107.3125...123341.8359375...121954.1328125...121116.6796875...120512.6015625...120008.921875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6501743197441101\n"
     ]
    }
   ],
   "source": [
    "# bma_gp_w_samples, chain_samples, sampler_stat = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_train, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "# Above the debug mode\n",
    "\n",
    "bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, None, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(chain_samples[:, 9, 31, 1], c='b', alpha=.3)\n",
    "# # plt.title('Traceplot')\n",
    "# # plt.plot(bma_gp_w_samples[1][:,9, 127, 1].numpy(), 'b')\n",
    "# # plt.xlabel('Iteration')\n",
    "# # plt.ylabel('Position')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for BAE/BNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "means_train_mcmc, X_train_mcmc, Y_train_mcmc = make_bma_samples(\n",
    "    X_train1, Y_train, base_preds_train, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_train,\n",
    "    seed=bma_seed, \n",
    "    prepare_mcmc_training=True)\n",
    "\n",
    "# Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "# It is used to generate final examples in `make_bne_samples()`.\n",
    "means_test_mcmc = make_bma_samples(\n",
    "    X_test1, None, base_preds_test, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_test,\n",
    "    seed=bma_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Additive Ensemble\n",
    "\n",
    "Given $\\mu(x)$ the posterior of a Bayesian ensemble model, the Bayesian Additive Ensemble is defined as:    \n",
    "\n",
    "$y \\sim N(\\mu(x) + r(x), \\sigma^2)$\n",
    "\n",
    "$r \\sim GaussianProcess(0, k)$\n",
    "\n",
    "The additive ensemble $r(x)$ services two purposes: \n",
    "\n",
    "1. Mitigates systematic bias in model prediction; \n",
    "2. Quantifies the model's epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # BNE GP Configs.\n",
    "# # lengthscale = 1. # @param\n",
    "# # l2_regularizer = 10. # @param\n",
    "\n",
    "# BNE model configs. \n",
    "# If estimate_mean=False, only estimates a constant variance on top of the \n",
    "# original model.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "# # MAP and MCMC configs\n",
    "# map_step_size=0.1 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=1e-2 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "                          l2_regularizer=bne_gp_l2_regularizer))\n",
    "bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "                             variance_prior_mean=variance_prior_mean,\n",
    "                             **bne_gp_config))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n"
     ]
    }
   ],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t18988.62890625...15931.923828125...15861.28515625...15824.08984375...15795.41015625...15773.033203125...15754.7421875...15737.87890625...15720.84375...15703.337890625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8144306540489197\n"
     ]
    }
   ],
   "source": [
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bae = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bae = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "\n",
    "# # dealing with NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Nonparametric Ensemble (Variance Only)\n",
    "So far, we are only estimating the mean-component of the model, i.e., we are assuming: \n",
    "\n",
    "$y \\sim Gaussian(m(x), \\sigma^2); \\quad m(x) = GP(0, k)$.\n",
    "\n",
    "By doing so, the model is implicitly assuming the distribution of $y$ is always a symmetric Gaussian distribution with constant mean across space and time. As a result, our model can only quantify model uncertainty (due to lack of data) via the GP prior, but cannot flexibly capture the data uncertainty that is inherent to the empirical distribution of y.\n",
    "\n",
    "To resolve this, we extend the ensemble's outcome distribution $y | f$ by also estimating the higher moments of the data distribution (e.g., variance, skewness, etc) using flexible estimators. Specifically, we specify the outcome distribution family to the [maximum-entropy distribution](https://en.wikipedia.org/wiki/Principle_of_maximum_entropy) given the known moments, so the predictive distribution is [minimax](https://arxiv.org/pdf/math/0410076.pdf) and still statistically efficient to estimate.\n",
    "\n",
    "For example, when we want to estimate the first two moments (mean and variance) of the distribution, this leads to a Gaussian distribution with spatio-temporally adaptive variance $\\sigma(x)^2$:\n",
    "\n",
    "$$y \\sim Gaussian(m(x), \\sigma(x)^2); \\quad \\mbox{where} \\quad m \\sim GP(0, k_m), \\sigma \\sim GP(0, k_\\sigma)$$\n",
    "\n",
    "and when we want to estimate the first three moments (mean and variance) of the distribution, this leads to a [Exponentially-modifed Gaussian](https://en.wikipedia.org/wiki/Exponentially_modified_Gaussian_distribution) (EMG) distribution with spatio-temporally adaptive variance $\\sigma(x)^2$ and skewness $\\lambda(x)$:\n",
    "\n",
    "$$y \\sim EMG(m(x), \\sigma(x)^2, \\lambda(x)); \\quad \\mbox{where} \\quad m \\sim GP(0, k_m), \\sigma \\sim GP(0, k_\\sigma), \\lambda \\sim GP(0, k_\\lambda)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model & Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t18560.0390625...16146.0869140625...15960.45703125...15895.189453125...15861.62890625...15838.482421875...15818.033203125...15799.189453125...15781.728515625...15765.9228515625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8152660131454468\n"
     ]
    }
   ],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "\n",
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bne_vo = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bne_vo = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88_VOXlgq9n_"
   },
   "source": [
    "## Bayesian Nonparametric Ensemble (Variance + Skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model & Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t18727.0078125...16512.93359375...16453.0...16425.234375...16398.06640625...16369.251953125...16338.7685546875...16307.216796875...16276.2314453125...16247.6259765625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7172572612762451\n"
     ]
    }
   ],
   "source": [
    "# Construct prior distribution.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bne_vs = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bne_vs = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_DATA_ADDR_PREFIX = \"./example/data\"\n",
    "# Tuning Parameters\n",
    "BMA_lenthscale = bma_gp_lengthscale\n",
    "#BNE_lenthscale = bne_gp_lengthscale\n",
    "BMA_L2 = bma_gp_l2_regularizer\n",
    "#BNE_L2 = bne_gp_l2_regularizer\n",
    "_SAVE_ADDR_PREFIX = \"./pic_1028/BMA_lenthscale_{}_L2_{}\".format(BMA_lenthscale, BMA_L2)\n",
    "\n",
    "path=_SAVE_ADDR_PREFIX\n",
    "isExists=os.path.exists(path) #判断路径是否存在，存在则返回true\n",
    "\n",
    "if not isExists:\n",
    "    os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The predictive surface of individual base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "monitors = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "\n",
    "base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]] = np.where(np.isnan(base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]]), 0, base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]])\n",
    "color_norm_base = make_color_norm(\n",
    "    base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]],   \n",
    "    method=\"percentile\")\n",
    "\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_model_{}_bmals_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(base_model_predictions_eastMA[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='RdYlGn_r',\n",
    "                         norm=color_norm_base, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The predictive surface of individual BNE gp weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_ensemble_weights = bma_joint_samples['ensemble_weights']\n",
    "ensemble_weights_val = tf.reduce_mean(bma_ensemble_weights, axis=0)\n",
    "\n",
    "weights_dict = {\n",
    "    \"AV\": ensemble_weights_val[:, 0],\n",
    "    \"GS\": ensemble_weights_val[:,1],\n",
    "    \"CACES\": ensemble_weights_val[:,2],\n",
    "}\n",
    "#weights_dict\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(weights_dict.values()),#[2],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_weights_var = np.var(bma_ensemble_weights, axis=0)\n",
    "weights_var_dict = {\n",
    "    \"AV\": ensemble_weights_var[:, 0],\n",
    "    \"GS\": ensemble_weights_var[:,1],\n",
    "    \"CACES\": ensemble_weights_var[:,2],\n",
    "}\n",
    "#weights_dict\n",
    "color_norm_weights_var = make_color_norm(\n",
    "    list(weights_var_dict.values()),#[0],   \n",
    "    method=\"percentile\")\n",
    "# display(ensemble_weights_val,ensemble_weights_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_names = [\"AV\", \"GS\", \"CACES\"]\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_weights_{}_bmals_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(weights_dict[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='viridis',\n",
    "                         norm=color_norm_weights, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         #save_addr='')\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot weights' variance\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_wvar_{}_bmals_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(weights_var_dict[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='viridis',\n",
    "                         norm=color_norm_weights_var, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         #save_addr='')\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The predictive surface of Y_mean, residual process, and Y_mean + residual process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BAE\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bae.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bae.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bae.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'BAE_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "                    save_addr=save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE vo\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bne_vo.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bne_vo.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bne_vo.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'BNEvo_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                                      save_addr=save_name)\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE v+s\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bne_vs.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bne_vs.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bne_vs.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'BNEvs_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(name, bma_gp_lengthscale, \n",
    "                                bma_gp_l2_regularizer, bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "                save_addr=save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.The predictive variance of Y_mean, residual process, and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAE\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bae.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bae.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bae.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'var_BAE_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE vo\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bne_vo.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bne_vo.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bne_vo.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'var_BNEvo_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE v+s\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bne_vs.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bne_vs.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bne_vs.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'var_BNEvs_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcc6cf470fa43d25f7728c2f3c746fc9b5580c34ff527761ed8536047e15184c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
