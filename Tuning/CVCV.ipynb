{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper_functions import *\n",
    "from ensemble import *\n",
    "from pygam import LinearGAM, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_eastMA = pd.read_csv('../data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('../data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('../data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "\n",
    "training51= pd.read_csv('../data/training_dataset/training51.csv')\n",
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "#base_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n",
    "\n",
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .07 # @param\n",
    "bma_gp_l2_regularizer = 0.15 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 1000 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n",
    "\n",
    "# BNE parameters.\n",
    "bne_gp_lengthscale = .1 # 5. # @param\n",
    "bne_gp_l2_regularizer = .05 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2) (24, 2) (27, 1) (24, 1) (27, 3) (24, 3)\n",
      "(28, 2) (23, 2) (28, 1) (23, 1) (28, 3) (23, 3)\n",
      "RMSE of LR: 1.6149733\n",
      "RMSE of GAM: 0.8605761731933875\n",
      "RMSE of BMA: nan\n",
      "[1.4032421, 1.8267046] [0.6138245166233582, 1.1073278297634168] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pygam/pygam.py:593: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  weights ** -1)**-0.5)\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pygam/pygam.py:752: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pygam/distributions.py:86: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  return (np.sum(weights * self.V(mu)**-1 * (y - mu)**2) /\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/pygam/pygam.py:752: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# find the index of max and min  for lon and lat\n",
    "min_index_lon = training_eastMA_noMI[['lon']].idxmin().values.tolist()\n",
    "max_index_lon = training_eastMA_noMI[['lon']].idxmax().values.tolist()\n",
    "min_index_lat = training_eastMA_noMI[['lat']].idxmin().values.tolist()\n",
    "max_index_lat = training_eastMA_noMI[['lat']].idxmax().values.tolist()\n",
    "# concetenate the index\n",
    "edge_list = min_index_lon + max_index_lon + min_index_lat + max_index_lat\n",
    "# exclude edge_list index from X_train1\n",
    "train_wo_edge = training_eastMA_noMI[~np.isin(np.arange(len(X_train1)), edge_list)]\n",
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=bma_seed)\n",
    "\n",
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "# concatenate train_wo_edge and edge_list index from training_eastMA_noMI\n",
    "train_new_order = pd.concat([train_wo_edge, training_eastMA_noMI.iloc[edge_list]])\n",
    "for train_index, test_index in kf.split(train_new_order[:-4]):\n",
    "    train_index = train_index.tolist() + edge_list\n",
    "\n",
    "    X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "    Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "    print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape, base_preds_tr.shape, base_preds_te.shape)\n",
    " \n",
    "    # Ref: linear regression\n",
    "    ref_model.fit(X_tr, Y_tr)\n",
    "    Y_pred = ref_model.predict(X_te)\n",
    "    rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "    #print(rmse_lr)\n",
    "\n",
    "    #GMA\n",
    "    ens_feature = np.asarray(list(base_preds_tr))\n",
    "    term_list = [s([3, 4], by=0), s([3, 4], by=1), s([3, 4], by=2)]\n",
    "    #term_list += [te(*list(ens_feature.shape[1] + np.array(range(X_tr.shape[1]))))]\n",
    "    #gam_feature_terms = TermList(*term_list)\n",
    "\n",
    "    gam_X_tr = np.concatenate([X_tr, base_preds_tr], axis=1)\n",
    "    gam_X_te = np.concatenate([X_te, base_preds_te], axis=1)\n",
    "    ref_gam = LinearGAM(s(3, 4, by=0)+s(3, 4, by=1)+s(3, 4, by=2)).fit(gam_X_tr, Y_tr)\n",
    "    #ref_gam = LinearGAM(te(0, 1, 2) + te(0, 1, 3) + te(0,1,4))\n",
    "    #gam = ref_gam.fit(gam_X_tr, Y_tr)\n",
    "    Y_pred = gam.predict(gam_X_te)\n",
    "    rmse_gam.append(rmse(Y_te, Y_pred.reshape(-1,1)))\n",
    "\n",
    "    #BMA\n",
    "   \n",
    "    # build model & run MCMC\n",
    "    # bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "    #                                 base_preds_tr, \n",
    "    #                                 **bma_model_config)\n",
    "\n",
    "    # bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "    # bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "    #                                        model_config=bma_model_config,\n",
    "    #                                        Y=Y_tr, \n",
    "    #                                        map_config=map_config,\n",
    "    #                                        mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "    # bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "    #                                  bma_weight_samples=bma_gp_w_samples[0],\n",
    "    #                                  bma_model_config=bma_model_config,\n",
    "    #                                  n_samples=bma_n_samples_eval, \n",
    "    #                                  seed=bne_seed,\n",
    "    #                                  y_samples_only=False)\n",
    "\n",
    "    # y_pred = bma_joint_samples['y']\n",
    "    # y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "\n",
    "    # rmse_bma.append(rmse(Y_te, y_pred))\n",
    "    #print(rmse_bma)\n",
    "print('RMSE of LR:', np.mean(rmse_lr)), print('RMSE of GAM:', np.mean(rmse_gam)), print('RMSE of BMA:', np.mean(rmse_bma))\n",
    "print(rmse_lr, rmse_gam, rmse_bma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
       "   max_iter=100, scale=None, terms=s(3) + s(3) + s(3) + intercept, \n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.sqrt(np.mean((Y_te - y_pred) ** 2))\n",
    "[s((3, 4), by=0), s([3, 4], by=1), s([3, 4], by=2)]\n",
    "ref_gam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('BNE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcc6cf470fa43d25f7728c2f3c746fc9b5580c34ff527761ed8536047e15184c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
