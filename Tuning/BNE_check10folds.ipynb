{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:39:38.719806: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:40:07.522488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Parameters Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred longitude max and min -69.93 -73.5\n",
      "pred latitude max and min 44.3 40.6\n",
      "train longitude max and min -70.023598 -73.443056\n",
      "train latitude max and min 44.107524 40.74529\n",
      "2011 center and scale:  [-72.185104  42.680347] [3.5699997 3.7000008]\n",
      "{'lengthscale': 0.55, 'l2_regularizer': 0.3, 'hidden_units': 128, 'y_noise_std': 0.01, 'activation_func': 'softmax'}\n",
      "{'gp_lengthscale': 0.55, 'gp_l2_regularizer': 0.3, 'y_noise_std': 0.01, 'map_step_size': 0.0005, 'map_num_steps': 10000, 'mcmc_step_size': 0.0001, 'mcmc_num_steps': 1000, 'mcmc_initialize_from_map': False, 'n_samples_eval': 250, 'n_samples_train': 100, 'n_samples_test': 250, 'seed': 0}\n",
      "{'gp_lengthscale': 7.5, 'gp_l2_regularizer': 10, 'variance_prior_mean': -2.5, 'skewness_prior_mean': -2.5, 'map_step_size': 0.0005, 'map_num_steps': 10000, 'mcmc_step_size': 0.0001, 'mcmc_num_steps': 1000, 'mcmc_nchain': 10, 'mcmc_burnin': 2500, 'mcmc_initialize_from_map': True, 'seed': 0}\n"
     ]
    }
   ],
   "source": [
    "# use BAE as the 1st step\n",
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n",
    "\n",
    "\n",
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .55 # @param\n",
    "bma_gp_l2_regularizer = .3 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n",
    "\n",
    "# ### Read training/prediction data\n",
    "training_eastMA = pd.read_csv('../data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('../data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('../data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())\n",
    "\n",
    "\n",
    "training51= pd.read_csv('../data/training_dataset/training51.csv')\n",
    "\n",
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)\n",
    "\n",
    "\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std,\n",
    "                             #activation='relu',\n",
    "                             activation_func='softmax'))\n",
    "print(bma_model_config)\n",
    "\n",
    "bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "                gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "                y_noise_std=y_noise_std,\n",
    "                map_step_size=map_step_size,\n",
    "                map_num_steps=map_num_steps,\n",
    "                mcmc_step_size=mcmc_step_size,\n",
    "                mcmc_num_steps=mcmc_num_steps,\n",
    "                mcmc_initialize_from_map=False,\n",
    "                n_samples_eval=bma_n_samples_eval,\n",
    "                n_samples_train=bma_n_samples_train,\n",
    "                n_samples_test=bma_n_samples_test,\n",
    "                seed=bma_seed)\n",
    "print(bma_config)\n",
    "\n",
    "\n",
    "\n",
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 7.5  # 5. # @param\n",
    "bne_gp_l2_regularizer = 10  # 15 # @param\n",
    "bne_variance_prior_mean = -2.5  # @param\n",
    "bne_skewness_prior_mean = -2.5  # @param\n",
    "bne_seed = 0  # @param\n",
    "bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "                  gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "                  variance_prior_mean=bne_variance_prior_mean,\n",
    "                  skewness_prior_mean=bne_skewness_prior_mean,\n",
    "                  map_step_size=map_step_size,\n",
    "                  map_num_steps=map_num_steps,\n",
    "                  mcmc_step_size=mcmc_step_size,\n",
    "                  mcmc_num_steps=mcmc_num_steps,\n",
    "                  mcmc_nchain=mcmc_nchain,\n",
    "                  mcmc_burnin=mcmc_burnin,\n",
    "                  mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "                  seed=bne_seed)\n",
    "\n",
    "print(bne_config)\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bae_bma_diff_line = []\n",
    "bae_bma_diff_df = pd.DataFrame(columns=['lon', 'lat', 'diff'])\n",
    "nll_lr_each, nll_gam_each, nll_bma_mean_each, nll_bma_each, nll_bae_each = [], [], [], [], []\n",
    "\n",
    "fold_num = 0\n",
    "kf = KFold(n_splits=10, random_state=bma_seed, shuffle=True)\n",
    "# rmse_bma_mean, rmse_bma2, rmse_bae = [], [], []\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "    fold_num += 1\n",
    "    #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_tr, X_te = X_train1[train_index], X_train1[test_index]\n",
    "    Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    base_preds_tr, base_preds_te = base_preds_train.numpy(\n",
    "    )[train_index], base_preds_train.numpy()[test_index]\n",
    "    print(train_index, test_index)\n",
    "    print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape,\n",
    "          base_preds_tr.shape, base_preds_te.shape)\n",
    "       \n",
    "    # Create data dictionary.\n",
    "    data_dicts = dict(X_train=X_tr,\n",
    "                      X_test=X_te,\n",
    "                      Y_train=Y_tr,\n",
    "                      base_preds_train=base_preds_tr,\n",
    "                      base_preds_test=base_preds_te)\n",
    "\n",
    "    print(Y_te)\n",
    "    # BMA-mean.\n",
    "    print('BMA-mean:', flush=True)\n",
    "    data_dict, bma_mean_joint_samples = get_bma_result(\n",
    "        data_dicts, bma_config=bma_config)\n",
    "    y_pred_bma_mean = np.mean(np.nan_to_num(\n",
    "        bma_mean_joint_samples['y']), axis=0)\n",
    "    print(y_pred_bma_mean)\n",
    "    pred_var_bma_mean = calc_prediction_std(y_pred_bma_mean, Y_te)\n",
    "    nll_bma_mean_each = (y_pred_bma_mean - Y_te)**2\n",
    "\n",
    "    # BMA.\n",
    "    print('BMA:', flush=True)\n",
    "    bma_var_config = bne_config.copy()\n",
    "    bma_var_config['mcmc_initialize_from_map'] = bma_config['mcmc_initialize_from_map']\n",
    "    bma_joint_samples = get_bne_result(data_dict, moment_mode='none',\n",
    "                                       bne_config=bma_var_config)\n",
    "    y_pred_bma = np.mean(np.nan_to_num(bma_joint_samples['y']), axis=0)\n",
    "    print(y_pred_bma)\n",
    "    pred_var_bma = calc_prediction_std(y_pred_bma, Y_te)\n",
    "    nll_bma_each = (y_pred_bma - Y_te)**2\n",
    "\n",
    "    # BAE.\n",
    "    print('BAE:', flush=True)\n",
    "    bae_joint_samples = get_bne_result(data_dict, moment_mode='mean',\n",
    "                                       bne_config=bne_config)\n",
    "    y_pred_bae = np.mean(np.nan_to_num(bae_joint_samples['y']), axis=0)\n",
    "    print(y_pred_bae)\n",
    "    pred_var_bae = calc_prediction_std(y_pred_bae, Y_te)\n",
    "    nll_bae_each = (y_pred_bae - Y_te)**2\n",
    "\n",
    "\n",
    "    bae_bma_diff = pd.DataFrame(columns=['lon', 'lat', 'diff'])\n",
    "    bae_bma_diff[\"lon\"] = X_te[:, 0]\n",
    "    bae_bma_diff[\"lat\"] = X_te[:, 1]\n",
    "    bae_bma_diff[\"diff\"] = nll_bae_each - nll_bma_mean_each\n",
    "    bae_bma_diff_df = bae_bma_diff_df.append(bae_bma_diff)\n",
    "\n",
    "    print(bae_bma_diff_df)\n",
    "    bae_bma_diff_line.append((pred_var_bae**2 - pred_var_bma_mean**2))\n",
    "    # larger points are more error\n",
    "    coordinate = np.asarray(base_model_predictions_eastMA[[\n",
    "                        \"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "\n",
    "    nll_list = [nll_bma_mean_each, nll_bma_each, nll_bae_each]\n",
    "    nll_list = np.asarray(nll_list)\n",
    "    nll_list = nll_list.reshape(-1, len(nll_bma_mean_each)*3)\n",
    "\n",
    "    color_norm_nll_each = make_color_norm(\n",
    "        nll_list.reshape(len(nll_list), -1),method='percentile')\n",
    "\n",
    "    # plot the bae_bma_diff_df\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(X_tr[:, 0] * X_scale[0] + X_centr[0], X_tr[:, 1] * X_scale[1] +\n",
    "            X_centr[1], c=\"black\", s=10, alpha=0.5, marker=\"s\")  # different shape\n",
    "    plt.scatter(X_te[:, 0] * X_scale[0] + X_centr[0], X_te[:, 1] * X_scale[1] + X_centr[1], c=nll_bma_mean_each,\n",
    "                s=abs(nll_bma_mean_each)*200, cmap='inferno_r', norm=color_norm_nll_each)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    plt.title(\"Fold \" + str(fold_num))\n",
    "\n",
    "    plt.xlim(min(coordinate[:, 0]), max(coordinate[:, 0]))\n",
    "    plt.ylim(min(coordinate[:, 1]), max(coordinate[:, 1]))\n",
    "    plt.show()\n",
    "\n",
    "    # plot the bae_bma_diff_df\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(X_tr[:, 0] * X_scale[0] + X_centr[0], X_tr[:, 1] * X_scale[1] +\n",
    "                X_centr[1], c=\"black\", s=10, alpha=0.5, marker=\"s\")  # different shape\n",
    "    plt.scatter(X_te[:, 0] * X_scale[0] + X_centr[0], X_te[:, 1] * X_scale[1] + X_centr[1], c=nll_bma_each,\n",
    "                s=abs(nll_bma_each)*200, cmap='inferno_r', norm=color_norm_nll_each)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    plt.title(\"Fold \" + str(fold_num))\n",
    "\n",
    "    plt.xlim(min(coordinate[:, 0]), max(coordinate[:, 0]))\n",
    "    plt.ylim(min(coordinate[:, 1]), max(coordinate[:, 1]))\n",
    "    plt.show()\n",
    "\n",
    "    # plot the bae_bma_diff_df\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(X_tr[:, 0] * X_scale[0] + X_centr[0], X_tr[:, 1] * X_scale[1] +\n",
    "            X_centr[1], c=\"black\", s=10, alpha=0.5, marker=\"s\")  # different shape\n",
    "    plt.scatter(X_te[:, 0] * X_scale[0] + X_centr[0], X_te[:, 1] * X_scale[1] + X_centr[1], c=nll_bae_each,\n",
    "                s=abs(nll_bae_each)*200, cmap='inferno_r', norm=color_norm_nll_each)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    plt.title(\"Fold \" + str(fold_num))\n",
    "\n",
    "    plt.xlim(min(coordinate[:, 0]), max(coordinate[:, 0]))\n",
    "    plt.ylim(min(coordinate[:, 1]), max(coordinate[:, 1]))\n",
    "    plt.show()  \n",
    "\n",
    "#print(bae_bma_diff_line)\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 28 2022, 07:24:34) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcc6cf470fa43d25f7728c2f3c746fc9b5580c34ff527761ed8536047e15184c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
